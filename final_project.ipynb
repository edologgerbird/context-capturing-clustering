{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading in the Twitter dataset as described in the synopsis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/xizhao/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/xizhao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xizhao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1', on_bad_lines='skip', names='target,user_id,date,flag,user,text'.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   target     user_id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>user_id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    800000\n4    800000\nName: target, dtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 20,000 rows from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sampling\n",
    "tweets = raw.groupby('target').apply(lambda x: x.sample(10000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    10000\n4    10000\nName: target, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   target     user_id                          date      flag            user  \\\n0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n\n                                                text  \n0  @xnausikaax oh no! where did u order from? tha...  \n1  A great hard training weekend is over.  a coup...  \n2  Right, off to work  Only 5 hours to go until I...  \n3                    I am craving for japanese food   \n4  Jean Michel Jarre concert tomorrow  gotta work...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>user_id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1974671194</td>\n      <td>Sat May 30 13:36:31 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>simba98</td>\n      <td>@xnausikaax oh no! where did u order from? tha...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1997882236</td>\n      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Seve76</td>\n      <td>A great hard training weekend is over.  a coup...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2177756662</td>\n      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>x__claireyy__x</td>\n      <td>Right, off to work  Only 5 hours to go until I...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2216838047</td>\n      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Balasi</td>\n      <td>I am craving for japanese food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1880666283</td>\n      <td>Fri May 22 02:03:31 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>djrickdawson</td>\n      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we write a function that cleans the data. I will detail what each line of code does to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this to each tweet\n",
    "def clean_data(tweet):\n",
    "    # removal of punctuations\n",
    "    tweet = re.sub(\"[^-9A-Za-z ]\", \"\" , tweet)\n",
    "    # convert to lowercase\n",
    "    tweet = \"\".join([i.lower() for i in tweet if i not in string.punctuation])\n",
    "    # tokenize the words temporarily\n",
    "    word_tokens = nltk.tokenize.word_tokenize(tweet)\n",
    "    # removal of non-alphabetical words\n",
    "    word_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    # removal of non-english words like usernames\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    word_tokens = [w for w in word_tokens if w in words]\n",
    "    # removal of stop-words\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    word_tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    # # stemming\n",
    "    # stemmer = nltk.stem.PorterStemmer()\n",
    "    # word_tokens = [stemmer.stem(w) for w in word_tokens]\n",
    "    # join back as string\n",
    "    tweet = \" \".join(word_tokens)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: @xnausikaax oh no! where did u order from? that's horrible \n",
      "Processed: oh u order thats horrible\n"
     ]
    }
   ],
   "source": [
    "# compare the tweet before and after processing\n",
    "print('Original:', tweets['text'][0])\n",
    "print('Processed:', clean_data(tweets['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(tweets.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   target     user_id                          date      flag            user  \\\n0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n\n                                        cleaned_text  \n0                          oh u order thats horrible  \n1  great hard training weekend couple days rest l...  \n2                                 right work go free  \n3                                       craving food  \n4           jean concert tomorrow got ta work though  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>user_id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1974671194</td>\n      <td>Sat May 30 13:36:31 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>simba98</td>\n      <td>oh u order thats horrible</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1997882236</td>\n      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Seve76</td>\n      <td>great hard training weekend couple days rest l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2177756662</td>\n      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>x__claireyy__x</td>\n      <td>right work go free</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2216838047</td>\n      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Balasi</td>\n      <td>craving food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1880666283</td>\n      <td>Fri May 22 02:03:31 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>djrickdawson</td>\n      <td>jean concert tomorrow got ta work though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['cleaned_text'] = tweets['text'].apply(clean_data)\n",
    "tweets = tweets.drop(columns=['text'])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "86"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the sampled dataset with pre-processed tweet text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(columns=['user_id', 'date', 'flag', 'user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   target                                       cleaned_text\n0       0                          oh u order thats horrible\n1       0  great hard training weekend couple days rest l...\n2       0                                 right work go free\n3       0                                       craving food\n4       0           jean concert tomorrow got ta work though",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh u order thats horrible</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>great hard training weekend couple days rest l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>right work go free</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>craving food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>jean concert tomorrow got ta work though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows that have missing null values for cleaned text. \n",
    "This ensures that the pre-trained model has no issues processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['target'] = tweets['target'].apply(lambda x: 1 if x==4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   target                                       cleaned_text\n0       0                          oh u order thats horrible\n1       0  great hard training weekend couple days rest l...\n2       0                                 right work go free\n3       0                                       craving food\n4       0           jean concert tomorrow got ta work though",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh u order thats horrible</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>great hard training weekend couple days rest l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>right work go free</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>craving food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>jean concert tomorrow got ta work though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we obtain the phrasal embeddings for each cleaned tweet text in the tweets dataframe.\n",
    "We use the GloVe Twitter 25 model, which contains pre-trained GloVe vectors based on 2 billion tweets, 27 billion tokens, and 1.2 million vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "model = api.load('glove-twitter-25')\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   target                                       cleaned_text  \\\n0       0                          oh u order thats horrible   \n1       0  great hard training weekend couple days rest l...   \n2       0                                 right work go free   \n3       0                                       craving food   \n4       0           jean concert tomorrow got ta work though   \n\n                                      tokenized_text  \n0  [[0.34172, -0.17305, 0.23311, 0.057375, -0.761...  \n1  [[-0.84229, 0.36512, -0.38841, -0.46118, 0.243...  \n2  [[-0.43876, 0.095692, 0.0030075, -0.13195, -0....  \n3  [[-1.2275, 0.61425, 0.23204, 0.4787, -0.55766,...  \n4  [[-0.70756, -1.2247, 0.087766, 0.27264, -0.412...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>cleaned_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh u order thats horrible</td>\n      <td>[[0.34172, -0.17305, 0.23311, 0.057375, -0.761...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>great hard training weekend couple days rest l...</td>\n      <td>[[-0.84229, 0.36512, -0.38841, -0.46118, 0.243...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>right work go free</td>\n      <td>[[-0.43876, 0.095692, 0.0030075, -0.13195, -0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>craving food</td>\n      <td>[[-1.2275, 0.61425, 0.23204, 0.4787, -0.55766,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>jean concert tomorrow got ta work though</td>\n      <td>[[-0.70756, -1.2247, 0.087766, 0.27264, -0.412...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes in a tweet and outputs a list of word embeddings for each word\n",
    "def get_embeddings(text):\n",
    "    return np.array([model[w] for w in text.split() if model.__contains__(w)])\n",
    "\n",
    "tweets['tokenized_text'] = tweets['cleaned_text'].apply(get_embeddings)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Cluster Points and Centroids\n",
    "\n",
    "In this section, we will define the cluster points and centroids in an OOP format. The requirements of each object class are as follows:\n",
    "\n",
    "Class VectorSpace:\n",
    "\n",
    "        Attributes:\n",
    "        - Points: List(Points)\n",
    "        - Centroids: List(Centroids)\n",
    "        - Points Look Up table: Dict{String : Point}\n",
    "        - Centroid Look Up table: Dict{String : Centroid}\n",
    "\n",
    "        Methods:\n",
    "        - Inject Points -> List(Points)\n",
    "        - Inject Centroids -> List(Points)\n",
    "        - Tweets to Vector Space -> True\n",
    "        - Vader to Vector Space -> True\n",
    "        - Calculate Cosine Similarity between 2 Points -> Float\n",
    "        - Get most similar centroid to a point and the similarity score -> Centroid, Float\n",
    "        - Assign Static Clusters -> Boolean\n",
    "        - Assign Dynamic Clusters -> Boolean\n",
    "        - Translate Document -> List(Float)\n",
    "        - Plot Points and Centroids -> plt\n",
    "\n",
    "Class Point:\n",
    "\n",
    "        Attributes:\n",
    "        - Vector Location: Array(Float)\n",
    "        - Closest centroid: Point\n",
    "        - Similarity with closest centroid: Float\n",
    "        - Polarity: Int\n",
    "\n",
    "        Methods:\n",
    "        - Calculate Cosine Similarity with own centroid -> Float\n",
    "        - Set centroid -> Boolean\n",
    "        - Set polarity -> Boolean\n",
    "        - Set similarity -> Boolean\n",
    "\n",
    "Class Centroid(Point):\n",
    "\n",
    "        Attributes:\n",
    "        - Super.Point Attributes\n",
    "        - Points assigned: List(Points)\n",
    "        \n",
    "        Methods:\n",
    "        - Reset cluster: Boolean\n",
    "        - Add Point to cluster: Boolean\n",
    "        - Update vector location: Array(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       target                                       cleaned_text  \\\n0           0                          oh u order thats horrible   \n1           0  great hard training weekend couple days rest l...   \n2           0                                 right work go free   \n3           0                                       craving food   \n4           0           jean concert tomorrow got ta work though   \n...       ...                                                ...   \n19995       1             arms morning baby face boy guitar hero   \n19996       1                  sweet mother extend royal welcome   \n19997       1             wouldnt mind watching derby mint julep   \n19998       1      shiny nice like shiny hate vista mean passion   \n19999       1                                       lake outside   \n\n                                          tokenized_text  \n0      [[ 3.4172e-01 -1.7305e-01  2.3311e-01  5.7375e...  \n1      [[-8.4229e-01  3.6512e-01 -3.8841e-01 -4.6118e...  \n2      [[-4.3876e-01  9.5692e-02  3.0075e-03 -1.3195e...  \n3      [[-1.2275    0.61425   0.23204   0.4787   -0.5...  \n4      [[-7.0756e-01 -1.2247e+00  8.7766e-02  2.7264e...  \n...                                                  ...  \n19995  [[-1.4197   -0.59392   0.034198  0.7004    0.1...  \n19996  [[-1.0864   -0.61674   0.33613   0.43232  -0.2...  \n19997  [[ 5.7749e-02  1.3264e+00 -1.6871e-02 -5.5858e...  \n19998  [[-9.4931e-01 -5.5718e-01  1.3540e-01 -1.2416e...  \n19999  [[-2.4857   -0.82327   0.31095  -0.42148  -1.6...  \n\n[20000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>cleaned_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh u order thats horrible</td>\n      <td>[[ 3.4172e-01 -1.7305e-01  2.3311e-01  5.7375e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>great hard training weekend couple days rest l...</td>\n      <td>[[-8.4229e-01  3.6512e-01 -3.8841e-01 -4.6118e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>right work go free</td>\n      <td>[[-4.3876e-01  9.5692e-02  3.0075e-03 -1.3195e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>craving food</td>\n      <td>[[-1.2275    0.61425   0.23204   0.4787   -0.5...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>jean concert tomorrow got ta work though</td>\n      <td>[[-7.0756e-01 -1.2247e+00  8.7766e-02  2.7264e...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1</td>\n      <td>arms morning baby face boy guitar hero</td>\n      <td>[[-1.4197   -0.59392   0.034198  0.7004    0.1...</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>1</td>\n      <td>sweet mother extend royal welcome</td>\n      <td>[[-1.0864   -0.61674   0.33613   0.43232  -0.2...</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>1</td>\n      <td>wouldnt mind watching derby mint julep</td>\n      <td>[[ 5.7749e-02  1.3264e+00 -1.6871e-02 -5.5858e...</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>1</td>\n      <td>shiny nice like shiny hate vista mean passion</td>\n      <td>[[-9.4931e-01 -5.5718e-01  1.3540e-01 -1.2416e...</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>1</td>\n      <td>lake outside</td>\n      <td>[[-2.4857   -0.82327   0.31095  -0.42148  -1.6...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = api.load('glove-twitter-25')\n",
    "tweets = pd.read_csv('tweets.csv', index_col=0)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    '''\n",
    "    A class used to represent each word in a document\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    word : str\n",
    "        The word represented by the point\n",
    "\n",
    "    vector : array\n",
    "        The vector representation of the word\n",
    "    \n",
    "    closest_centroid : Centroid\n",
    "        The closest centroid to the point\n",
    "\n",
    "    cosine_similarity_with_centroid : Centroid (Float?)\n",
    "        The cosine similarity with the point's closest centroid\n",
    "\n",
    "    polarity : Float\n",
    "        The polarity of the point as determined by the polarity of its closest centroid\n",
    "\n",
    "\n",
    "    Methods\n",
    "    ----------\n",
    "    set_centroid(centroid)\n",
    "        Stores the centroid the point is assigned to\n",
    "\n",
    "    set_consine_similarity_with_centroid(similarity)\n",
    "        Sets the cosine similarity between the point and its closest centroid\n",
    "\n",
    "    set_polarity(polarity)\n",
    "        Sets the polarity of the point as determined by the polarity of its closest centroid\n",
    "\n",
    "    '''\n",
    "    def __init__(self, word, model):\n",
    "        self.word = word\n",
    "        self.vector = model[word] if model.__contains__(word) else None\n",
    "        self.closest_centroid = None\n",
    "        self.cosine_similarity_with_centroid = None\n",
    "        self.polarity = None\n",
    "\n",
    "    def set_centroid(self, centroid):\n",
    "        self.centroid = centroid\n",
    "        return True\n",
    "\n",
    "    def set_consine_similarity_with_centroid(self, similarity):\n",
    "        self.cosine_similarity_with_centroid = similarity\n",
    "        return True\n",
    "\n",
    "    def set_polarity(self, polarity):\n",
    "        self.polarity = polarity\n",
    "        return True\n",
    "\n",
    "    def get_cosine_similarity_with_centroid(self, mean_distance=False):\n",
    "        if self.closest_centroid is not None:\n",
    "            if not mean_distance:\n",
    "                return self.cosine_similarity_with_centroid\n",
    "            else:\n",
    "                return np.mean([point.cosine_similarity_with_centroid for point in self.closest_centroid.points])\n",
    "        else:\n",
    "            raise Exception('Unable to calculate cosine similarity with NoneType: Centroid is undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centroid(Point):\n",
    "    '''\n",
    "    A class used to represent each word in the lexical dictionary as a centroid. \n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    word : str\n",
    "        The word represented by the point\n",
    "\n",
    "    vector : array\n",
    "        The vector representation of the word\n",
    "    \n",
    "    closest_centroid : Centroid\n",
    "        The closest centroid to the point\n",
    "\n",
    "    cosine_similarity_with_centroid : Centroid\n",
    "        The cosine similarity with the point's closest centroid\n",
    "\n",
    "    polarity : Float\n",
    "        The polarity of the point as determined by the polarity of its closest centroid\n",
    "\n",
    "    cluster_points : List(Points)\n",
    "        A list containing the Points assigned to the centroid as a cluster\n",
    "\n",
    "\n",
    "    Methods\n",
    "    ----------\n",
    "    reset_cluster()\n",
    "        resets the cluster to an empty list\n",
    "\n",
    "    add_point_to_cluster(point, similarity)\n",
    "        adds a Point to the centroid's cluster. Updates the Point's polarity, centroid and cosine similarity with that of and with the Centroid\n",
    "\n",
    "    update_vector_location()\n",
    "        For use in the dynamic clustering algorithm. Updates the vector location to the mean of all its points.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, word, polarity, model):\n",
    "        super.__init__(word, model)\n",
    "        self.polarity = polarity\n",
    "        self.cluster_points = []\n",
    "\n",
    "    def reset_cluster(self):\n",
    "        self.cluster_points = []\n",
    "        return True\n",
    "\n",
    "    def add_point_to_cluster(self, point, similarity):\n",
    "        self.cluster_points.append(point)\n",
    "        point.set_polarity(self.polarity)\n",
    "        point.set_centroid(self)\n",
    "        point.set_set_consine_similarity_with_centroid(similarity)\n",
    "        return True\n",
    "\n",
    "    def update_vector_location(self):\n",
    "        cluster_mean = sum([point.vector for point in self.cluster_points])/len(self.cluster_points)\n",
    "        self.vector = cluster_mean\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSpace:\n",
    "    '''\n",
    "    A class used to represent the Vector Space which will contain the points and centroids. \n",
    "    Separate VectorSpaces should be used for the Static and Dynamic Clustering approaches respectively.\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    points : List(Points)\n",
    "        The list of Points within the vector space.\n",
    "\n",
    "    centroids : List(Centroids)\n",
    "        The list of Centroids within the vector space.\n",
    "\n",
    "    points_look_up_table : Dict(Str:Point)\n",
    "        A look-up table to store the reference Points of each word. Allows for efficient translation of text to Point attributes\n",
    "    \n",
    "    centroids_look_up_table : Dict(Str:Point)\n",
    "        A look-up table to store the reference Centroid of each word. Allows for efficient translation of text to Centroid attributes\n",
    "\n",
    "\n",
    "    Methods\n",
    "    ----------\n",
    "    inject_point(point)\n",
    "        Injects a point into the vector space and updates the Points look-up table.\n",
    "\n",
    "    inject_centroid(centroid)\n",
    "        Injects a centroid into the vector space and updates the Centroids look-up table\n",
    "\n",
    "    tweet_to_vector_space(tweet, model)\n",
    "        Converts a tweet, aka document, of words into their respective points and injects the points into the vector space. \n",
    "        The model is the embedding model used to tokenise the text.\n",
    "        If the model does not contain the word, the Point is not created.\n",
    "\n",
    "    vader_to_vector_space(word, polarity, model)\n",
    "        Converts a word from the sentiment lexical dictionary into a Centroid and injects it into the vector space.\n",
    "        The model is the embedding model used to tokenise the text.\n",
    "        If the model does not contain the word, the Centroid is not created.\n",
    "\n",
    "    calculate_cosine_similarity(point1, point2)\n",
    "        Calculates the cosine similarity between 2 Points\n",
    "\n",
    "    get_most_similar_centroid(point)\n",
    "        Locates the closest Centroid to the Point from all the Centroids within the VectorSpace based on Cosine Similarity. \n",
    "        Returns the closest centroid and the Cosine Similarity between the point and the Centroid.\n",
    "\n",
    "    assign_static_clusters()\n",
    "        Executes the static clustering algorithm based on the paper \"Improvement of Sentiment Analysis based on clustring of Word2Vec\".\n",
    "\n",
    "    assign_dynamic_clusters()\n",
    "        Executes the proposed dynamic clustering algorithm.\n",
    "\n",
    "    translate_document(document, static=False, dynamic=False)\n",
    "        Translates a document of words into their respective similarity scores. \n",
    "        If a Centroid has negative polarity, the similarity will be transformed by a multiplicative factor of -1\n",
    "        If static, the mean similarity scores of all the points within a certain centroid will be returned for all these Points.\n",
    "        If dynamic, the raw similary will be returned\n",
    "\n",
    "    plot_points(n)\n",
    "        Plots the first n unique Points and Centroids on a 2-dimensional plane.\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.points = []\n",
    "        self.centroids = []\n",
    "        self.points_look_up_table = {}\n",
    "        self.centroids_look_up_table = {}\n",
    "\n",
    "    def inject_point(self, point):\n",
    "        self.points.append(point)\n",
    "        self.points_look_up_table[point.word] = point\n",
    "        return True\n",
    "    \n",
    "    def inject_centroid(self, centroid):\n",
    "        self.centroids.append(centroid)\n",
    "        self.centroids_look_up_table[centroid.word] = centroid\n",
    "        return True\n",
    "\n",
    "    def tweet_to_vector_space(self, tweet, model):\n",
    "        for word in tweet.split():\n",
    "            if model.__contains__(word):\n",
    "                self.inject_point(Point(word, model))\n",
    "            else:\n",
    "                print(f\"INFO: Model does not contain {word}\")\n",
    "        return True\n",
    "\n",
    "    def vader_to_vector_space(self, word, polarity, model):\n",
    "        if model.__contains__(word):\n",
    "            self.inject_centroid(Centroid(word, polarity, model))\n",
    "        return True\n",
    "\n",
    "    def calculate_cosine_similarity(self, point1, point2):\n",
    "        return cosine_similarity(point1.vector, point2.vector)\n",
    "\n",
    "    def get_most_similar_centroid(self, point):\n",
    "        most_similar_centroid = None\n",
    "        max_similarity = 0\n",
    "\n",
    "        for centroid in self.centroids:\n",
    "            similarity = self.calculate_cosine_similarity(point, centroid)\n",
    "            if similarity > most_similar_centroid:\n",
    "                most_similar_centroid = centroid\n",
    "                max_similarity = similarity\n",
    "\n",
    "        return most_similar_centroid, max_similarity\n",
    "\n",
    "    def assign_static_clusters(self):\n",
    "        # Implement static cluster algorithm\n",
    "        for point in self.points:\n",
    "            most_similar_centroid, max_similarity = self.get_most_similar_centroid(point)\n",
    "            most_similar_centroid.add_point_to_cluster(point, max_similarity)\n",
    "        return True\n",
    "\n",
    "    def assign_dynamic_clusters(self, iterations = 10):\n",
    "        # Implement dynamic cluster algorithm\n",
    "        self.assign_static_clusters\n",
    "        for i in range(iterations):\n",
    "            for centroid in self.centroids:\n",
    "                centroid.update_vector_location\n",
    "            self.assign_static_clusters\n",
    "        return True\n",
    "\n",
    "    def translate_document(self, document, static=False, dynamic=False):\n",
    "        output = []\n",
    "        if static:\n",
    "            for word in document:\n",
    "                similarity_score = self.points_look_up_table[word].get_cosine_similarity_with_centroid(mean_distance=True)\n",
    "                if self.points_look_up_table[word].polarity < 0:\n",
    "                    similarity_score = -similarity_score\n",
    "                output.append(similarity_score)\n",
    "\n",
    "        elif dynamic:\n",
    "            for word in document:\n",
    "                similarity_score = self.points_look_up_table[word].get_cosine_similarity_with_centroid(mean_distance=False)\n",
    "                if self.points_look_up_table[word].polarity < 0:\n",
    "                    similarity_score = -similarity_score\n",
    "                output.append(similarity_score)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def plot_points(self, n):\n",
    "        words = []\n",
    "        vectors = []\n",
    "        for point in self.points:\n",
    "            if point.word not in words:\n",
    "                words.append(point.word)\n",
    "                vectors.append(point.vector)\n",
    "\n",
    "        words = np.asarray(words)[:n]\n",
    "        vectors = np.array(vectors)[:n]\n",
    "        \n",
    "        tsne = TSNE(n_components=2)\n",
    "        X_tsne = tsne.fit_transform(vectors)\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "        for label, x, y in zip(words, X_tsne[:, 0], X_tsne[:, 1]):\n",
    "            plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords=\"offset points\")\n",
    "        plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Injecting Tweets into Vector Space\n",
    "\n",
    "In this section, we will initialise a VectorSpace, and populate it with words from the Tweets. At the same time, we will maintain a hashtable to keep track of the corresponding point for each word that we can translate the points back to words in the form of the respective maximum similarity value in O(1) time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "   target                                       cleaned_text  \\\n0       0                          oh u order thats horrible   \n1       0  great hard training weekend couple days rest l...   \n2       0                                 right work go free   \n3       0                                       craving food   \n4       0           jean concert tomorrow got ta work though   \n\n                                      tokenized_text  \n0  [[ 3.4172e-01 -1.7305e-01  2.3311e-01  5.7375e...  \n1  [[-8.4229e-01  3.6512e-01 -3.8841e-01 -4.6118e...  \n2  [[-4.3876e-01  9.5692e-02  3.0075e-03 -1.3195e...  \n3  [[-1.2275    0.61425   0.23204   0.4787   -0.5...  \n4  [[-7.0756e-01 -1.2247e+00  8.7766e-02  2.7264e...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>cleaned_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh u order thats horrible</td>\n      <td>[[ 3.4172e-01 -1.7305e-01  2.3311e-01  5.7375e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>great hard training weekend couple days rest l...</td>\n      <td>[[-8.4229e-01  3.6512e-01 -3.8841e-01 -4.6118e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>right work go free</td>\n      <td>[[-4.3876e-01  9.5692e-02  3.0075e-03 -1.3195e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>craving food</td>\n      <td>[[-1.2275    0.61425   0.23204   0.4787   -0.5...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>jean concert tomorrow got ta work though</td>\n      <td>[[-7.0756e-01 -1.2247e+00  8.7766e-02  2.7264e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def cal_polarity_of_tweet(cleaned_text, vector_space):\n",
    "    '''\n",
    "    calculating the polarity of the tweet by combining individual polarity of the words\n",
    "    :param cleaned_text:\n",
    "    :return: polarity score of the tweet\n",
    "    '''\n",
    "    Polarity = []\n",
    "    for word in cleaned_text.split():\n",
    "        point = vector_space.points_look_up_table[word]\n",
    "        Polarity.append(point.polarity)\n",
    "    polarity = 1 if np.mean(Polarity) >= 0.5 else 0\n",
    "\n",
    "    return polarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### obtaining vader lexicons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# obtaining Vader Sentiment lexicons\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "lexicons = analyzer.lexicon  # total: 7506"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4880\n"
     ]
    }
   ],
   "source": [
    "# filter lexicons to keep those that also appear in vocab\n",
    "vocab = model.index_to_key\n",
    "lexicons_filtered = {k: v for k, v in lexicons.items() if k in vocab}\n",
    "print(len(lexicons_filtered)) # total: 4880"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':-o': 1, ':-[': 0, ':-\\\\': 0, ':@': 0, ':o': 0, ':[': 0, ':\\\\': 0, ':]': 1, ':o)': 1, ':o|': 0, ':{': 0, ';-]': 1, ';]': 1, '=\\\\': 0, '=]': 1, '>:o': 0, '>:[': 0, '>:\\\\': 0, 'aas': 1, 'afu': 0, 'alol': 1, 'aml': 1, 'atab': 0, 'awol': 0, 'ayc': 1, 'ayor': 0, 'bfd': 0, 'bfe': 0, 'bff': 1, 'bl': 1, 'bsod': 0, 'btd': 0, 'bz': 1, 'doa': 0, 'dx': 0, 'ez': 1, 'fav': 1, 'ff': 1, 'ffs': 0, 'fkm': 0, 'ftw': 1, 'fu': 0, 'fubar': 0, 'fwb': 1, 'fyi': 1, 'gg': 1, 'gga': 1, 'gigo': 0, 'gj': 1, 'gl': 1, 'gla': 1, 'gn': 1, 'grrr': 0, 'gt': 1, 'h&k': 1, 'hagd': 1, 'hagn': 1, 'hago': 1, 'hak': 1, 'hand': 1, 'heart': 1, 'hearts': 1, 'hugz': 1, 'idk': 0, 'ijs': 1, 'ilu': 1, 'ily': 1, 'iou': 1, 'iyq': 1, 'jho': 1, 'jj': 1, 'jk': 1, 'jp': 1, 'jt': 1, 'jw': 1, 'kfy': 1, 'kia': 0, 'kk': 1, 'l': 1, 'l&r': 1, 'lmao': 1, 'lmbao': 1, 'lmfao': 1, 'lmso': 1, 'lol': 1, 'lolz': 1, 'lts': 1, 'ly': 1, 'lya': 1, 'lyb': 1, 'lyl': 1, 'lylas': 1, 'mia': 0, 'mml': 1, 'mofo': 0, 'muah': 1, 'mwah': 1, 'nbd': 1, 'nfc': 0, 'nfw': 0, 'nh': 1, 'nimby': 0, 'nme': 0, 'np': 1, 'o.o': 0, 'ok': 1, 'o_o': 0, 'pita': 0, 'pls': 1, 'plz': 1, 'po': 0, 'ptl': 1, 'pu': 0, 'qq': 0, 'qt': 1, 'r&r': 1, 'rofl': 1, 'roflmao': 1, 'rotfl': 1, 'rotflmao': 1, 'rotflmfao': 1, 'rotflol': 1, 'sete': 1, 'slap': 1, 'slaw': 1, 'smh': 0, 'snafu': 0, 'sob': 0, 'swak': 1, 'tgif': 1, 'thks': 1, 'thx': 1, 'tia': 1, 'tmi': 0, 'tnx': 1, 'true': 1, 'tx': 1, 'txs': 1, 'ty': 1, 'tyvm': 1, 'urw': 1, 'vbg': 1, 'vbs': 1, 'vip': 1, 'wag': 0, 'wd': 1, 'wilco': 1, 'wp': 1, 'wtf': 0, 'wtg': 1, 'wth': 0, 'x-d': 1, 'x-p': 1, 'xd': 1, 'xoxo': 1, 'xp': 1, 'xtc': 1, 'yolo': 1, 'yoyo': 1, 'yvw': 1, 'yw': 1, 'zzz': 0, 'abandon': 0, 'abandoned': 0, 'abandoning': 0, 'abandonment': 0, 'abandons': 0, 'abducted': 0, 'abduction': 0, 'abductions': 0, 'abhor': 0, 'abhorrent': 0, 'abhors': 0, 'abilities': 1, 'ability': 1, 'aboard': 1, 'absentee': 0, 'absentees': 0, 'absolve': 1, 'absolved': 1, 'absolves': 1, 'abuse': 0, 'abused': 0, 'abuser': 0, 'abusers': 0, 'abuses': 0, 'abusing': 0, 'abusive': 0, 'accept': 1, 'acceptability': 1, 'acceptable': 1, 'acceptably': 1, 'acceptance': 1, 'acceptances': 1, 'acceptant': 1, 'acceptation': 1, 'accepted': 1, 'accepting': 1, 'accepts': 1, 'accident': 0, 'accidental': 0, 'accidentally': 0, 'accidents': 0, 'accomplish': 1, 'accomplished': 1, 'accomplishes': 1, 'accusation': 0, 'accusations': 0, 'accuse': 0, 'accused': 0, 'accuses': 0, 'accusing': 0, 'ache': 0, 'ached': 0, 'aches': 0, 'achievable': 1, 'aching': 0, 'acquit': 1, 'acquits': 1, 'acquitted': 1, 'active': 1, 'actively': 1, 'actives': 1, 'adequate': 1, 'admirable': 1, 'admirably': 1, 'admiral': 1, 'admirals': 1, 'admiralty': 1, 'admiration': 1, 'admire': 1, 'admired': 1, 'admirer': 1, 'admirers': 1, 'admires': 1, 'admiring': 1, 'admit': 1, 'admits': 1, 'admitted': 1, 'adopt': 1, 'adopts': 1, 'adorable': 1, 'adorableness': 1, 'adorably': 1, 'adoration': 1, 'adore': 1, 'adored': 1, 'adorer': 1, 'adores': 1, 'adoring': 1, 'adorn': 1, 'adorned': 1, 'adorning': 1, 'adornment': 1, 'adorns': 1, 'advanced': 1, 'advantage': 1, 'advantaged': 1, 'advantageous': 1, 'advantages': 1, 'adventure': 1, 'adventurer': 1, 'adventurers': 1, 'adventures': 1, 'adventuring': 1, 'adventurous': 1, 'adversarial': 0, 'adversaries': 0, 'adversary': 0, 'adverse': 0, 'adversely': 0, 'adversities': 0, 'adversity': 0, 'affected': 0, 'affection': 1, 'affectionate': 1, 'affectionately': 1, 'affections': 1, 'afflicted': 0, 'aggravate': 0, 'aggravated': 0, 'aggravates': 0, 'aggravating': 0, 'aggression': 0, 'aggressive': 0, 'aggressively': 0, 'aggressiveness': 0, 'aggressor': 0, 'aggressors': 0, 'aghast': 0, 'agitate': 0, 'agitated': 0, 'agitates': 0, 'agitating': 0, 'agitation': 0, 'agitato': 0, 'agitator': 0, 'agog': 1, 'agonise': 0, 'agonising': 0, 'agonize': 0, 'agonized': 0, 'agonizing': 0, 'agony': 0, 'agree': 1, 'agreeable': 1, 'agreeably': 1, 'agreed': 1, 'agreeing': 1, 'agreement': 1, 'agreements': 1, 'agrees': 1, 'alarm': 0, 'alarmed': 0, 'alarming': 0, 'alarmingly': 0, 'alarmists': 0, 'alarms': 0, 'alas': 0, 'alert': 1, 'alienation': 0, 'alive': 1, 'allergic': 0, 'allow': 1, 'alone': 0, 'alright': 1, 'amaze': 1, 'amazed': 1, 'amazement': 1, 'amazes': 1, 'amazing': 1, 'amazon': 1, 'amazonite': 1, 'amazons': 0, 'ambitious': 1, 'ambivalent': 1, 'amor': 1, 'amoral': 0, 'amorino': 1, 'amoroso': 1, 'amorous': 1, 'amorphous': 0, 'amort': 0, 'amortization': 1, 'amuse': 1, 'amused': 1, 'amusement': 1, 'amusements': 1, 'amuser': 1, 'amuses': 1, 'amusing': 1, 'amusingly': 1, 'anger': 0, 'angered': 0, 'angering': 0, 'angers': 0, 'angrier': 0, 'angriest': 0, 'angrily': 0, 'angry': 0, 'anguish': 0, 'anguished': 0, 'animosity': 0, 'annoy': 0, 'annoyance': 0, 'annoyances': 0, 'annoyed': 0, 'annoying': 0, 'annoys': 0, 'antagonism': 0, 'antagonist': 0, 'antagonistic': 0, 'antagonists': 0, 'antagonize': 0, 'antagonizing': 0, 'anti': 0, 'anticipation': 1, 'anxieties': 0, 'anxiety': 0, 'anxious': 0, 'anxiously': 0, 'anxiousness': 0, 'aok': 1, 'apathetic': 0, 'apathy': 0, 'apeshit': 0, 'apocalyptic': 0, 'apologise': 1, 'apologised': 1, 'apologises': 1, 'apologising': 1, 'apologize': 1, 'apologized': 1, 'apologizes': 1, 'apologizing': 0, 'apology': 1, 'appalled': 0, 'appalling': 0, 'appallingly': 0, 'appease': 1, 'appeased': 1, 'appeasing': 1, 'applaud': 1, 'applauded': 1, 'applauding': 1, 'applauds': 1, 'applause': 1, 'appreciate': 1, 'appreciated': 1, 'appreciates': 1, 'appreciating': 1, 'appreciation': 1, 'appreciations': 1, 'appreciative': 1, 'apprehension': 0, 'approval': 1, 'approved': 1, 'approves': 1, 'ardent': 1, 'arguable': 0, 'arguably': 0, 'argue': 0, 'argued': 0, 'argues': 0, 'arguing': 0, 'argument': 0, 'argumentative': 0, 'arguments': 0, 'arrest': 0, 'arrested': 0, 'arrests': 0, 'arrogance': 0, 'arrogant': 0, 'arrogantly': 0, 'ashamed': 0, 'ass': 0, 'assassination': 0, 'assassinations': 0, 'assault': 0, 'assaulted': 0, 'assaulting': 0, 'assaults': 0, 'asset': 1, 'assets': 1, 'assfucking': 0, 'assholes': 0, 'assurance': 1, 'assurances': 1, 'assure': 1, 'assured': 1, 'assuredly': 1, 'assurer': 1, 'assures': 1, 'assuring': 1, 'astonished': 1, 'astound': 1, 'astounded': 1, 'astounding': 1, 'astoundingly': 1, 'astounds': 1, 'attachment': 1, 'attachments': 1, 'attack': 0, 'attacked': 0, 'attacker': 0, 'attackers': 0, 'attacking': 0, 'attacks': 0, 'attract': 1, 'attracted': 1, 'attracting': 1, 'attraction': 1, 'attractions': 1, 'attractive': 1, 'attractively': 1, 'attractiveness': 1, 'attracts': 1, 'audacious': 1, 'authority': 1, 'aversion': 0, 'avert': 0, 'averted': 0, 'averts': 0, 'avid': 1, 'avoid': 0, 'avoidance': 0, 'avoided': 0, 'avoider': 0, 'avoiders': 0, 'avoiding': 0, 'avoids': 0, 'await': 1, 'awaited': 0, 'awaits': 1, 'award': 1, 'awarded': 1, 'awardee': 1, 'awardees': 1, 'awarding': 1, 'awards': 1, 'awesome': 1, 'awful': 0, 'awkward': 0, 'awkwardly': 0, 'awkwardness': 0, 'axe': 0, 'axed': 0, 'backed': 1, 'backing': 1, 'backs': 0, 'bad': 0, 'badass': 1, 'badly': 0, 'bailout': 0, 'bamboozle': 0, 'bamboozled': 0, 'ban': 0, 'banish': 0, 'bankrupt': 0, 'bankster': 0, 'banned': 0, 'bargain': 1, 'barrier': 0, 'bashful': 0, 'bastard': 0, 'bastardized': 0, 'bastards': 0, 'battle': 0, 'battled': 0, 'battlefield': 0, 'battlefields': 0, 'battlefront': 0, 'battleground': 0, 'battlegrounds': 0, 'battler': 0, 'battlers': 0, 'battles': 0, 'battleship': 0, 'battleships': 0, 'battling': 0, 'beaten': 0, 'beating': 0, 'beaut': 1, 'beauteous': 1, 'beautician': 1, 'beauticians': 1, 'beauties': 1, 'beautification': 1, 'beautified': 1, 'beautifies': 1, 'beautiful': 1, 'beautifuler': 1, 'beautifulest': 1, 'beautifully': 1, 'beautifulness': 1, 'beautify': 1, 'beautifying': 1, 'beauts': 1, 'beauty': 1, 'belittle': 0, 'belittled': 0, 'beloved': 1, 'benefic': 1, 'beneficent': 1, 'beneficial': 1, 'beneficiaries': 1, 'beneficiary': 1, 'benefit': 1, 'benefits': 1, 'benefitted': 1, 'benefitting': 1, 'benevolence': 1, 'benevolent': 1, 'benign': 1, 'bereaved': 0, 'best': 1, 'betray': 0, 'betrayal': 0, 'betrayed': 0, 'betraying': 0, 'betrays': 0, 'better': 1, 'bias': 0, 'biased': 0, 'bitch': 0, 'bitched': 0, 'bitchery': 0, 'bitches': 0, 'bitchier': 0, 'bitchiest': 0, 'bitchiness': 0, 'bitching': 0, 'bitchy': 0, 'bitter': 0, 'bitterest': 0, 'bitterly': 0, 'bittern': 0, 'bitterness': 0, 'bitters': 0, 'bittersweet': 0, 'bizarre': 0, 'blah': 0, 'blam': 0, 'blame': 0, 'blamed': 0, 'blameless': 1, 'blames': 0, 'blaming': 0, 'bless': 1, 'blessed': 1, 'blessedness': 1, 'blesser': 1, 'blesses': 1, 'blessing': 1, 'blessings': 1, 'blind': 0, 'bliss': 1, 'blissful': 1, 'blithe': 1, 'block': 0, 'blockbuster': 1, 'blocked': 0, 'blocking': 0, 'blocks': 0, 'bloody': 0, 'blurry': 0, 'bold': 1, 'bolder': 1, 'boldest': 1, 'boldly': 1, 'boldness': 1, 'bomb': 0, 'bonus': 1, 'bonuses': 1, 'boost': 1, 'boosted': 1, 'boosting': 1, 'boosts': 1, 'bore': 0, 'boreal': 0, 'bored': 0, 'boredom': 0, 'borer': 0, 'bores': 0, 'boring': 0, 'bother': 0, 'bothered': 0, 'bothering': 0, 'bothers': 0, 'bothersome': 0, 'boycott': 0, 'boycotted': 0, 'boycotting': 0, 'boycotts': 0, 'brainwashing': 0, 'brave': 1, 'braved': 1, 'bravely': 1, 'braver': 1, 'bravery': 1, 'braves': 1, 'bravest': 1, 'breathtaking': 1, 'bribe': 0, 'bright': 1, 'brighten': 1, 'brightened': 1, 'brightener': 1, 'brightening': 1, 'brightens': 1, 'brighter': 1, 'brightest': 1, 'brightly': 1, 'brightness': 1, 'brights': 1, 'brilliance': 1, 'brilliancy': 1, 'brilliant': 1, 'brilliantly': 1, 'brilliants': 1, 'brisk': 1, 'broke': 0, 'broken': 0, 'brooding': 1, 'brutal': 0, 'brutality': 0, 'brutalize': 0, 'brutalized': 0, 'brutally': 0, 'bullied': 0, 'bullshit': 0, 'bully': 0, 'bullying': 0, 'bummer': 0, 'buoyant': 1, 'burden': 0, 'burdened': 0, 'burdening': 0, 'burdens': 0, 'burdensome': 0, 'bwahaha': 1, 'bwahahah': 1, 'calm': 1, 'calmed': 1, 'calmer': 1, 'calmest': 1, 'calming': 1, 'calmly': 1, 'calmness': 1, 'calms': 1, 'cancel': 0, 'cancelled': 0, 'cancelling': 0, 'cancels': 0, 'cancer': 0, 'capable': 1, 'captivated': 1, 'care': 1, 'cared': 1, 'carefree': 1, 'careful': 1, 'carefully': 1, 'careless': 0, 'carelessly': 0, 'carelessness': 0, 'cares': 1, 'caring': 1, 'casual': 1, 'casually': 1, 'casualty': 0, 'catastrophe': 0, 'catastrophic': 0, 'cautious': 0, 'celebrate': 1, 'celebrated': 1, 'celebrates': 1, 'celebrating': 1, 'censor': 0, 'censored': 0, 'censors': 0, 'certain': 1, 'certainly': 1, 'certainties': 1, 'certainty': 1, 'chagrin': 0, 'challenge': 1, 'challenged': 0, 'challenger': 1, 'challengers': 1, 'challenges': 1, 'challenging': 1, 'champ': 1, 'champagne': 1, 'champagnes': 1, 'champaign': 1, 'champers': 1, 'champignon': 1, 'champignons': 1, 'champion': 1, 'championed': 1, 'championing': 1, 'champions': 1, 'championship': 1, 'championships': 1, 'champs': 1, 'champy': 1, 'chance': 1, 'chances': 1, 'chaos': 0, 'chaotic': 0, 'charged': 0, 'charges': 0, 'charitable': 1, 'charities': 1, 'charity': 1, 'charm': 1, 'charmed': 1, 'charmer': 1, 'charmers': 1, 'charmeuse': 1, 'charming': 1, 'charmingly': 1, 'charms': 1, 'chastise': 0, 'chastised': 0, 'chastises': 0, 'chastising': 0, 'cheat': 0, 'cheated': 0, 'cheater': 0, 'cheaters': 0, 'cheating': 0, 'cheats': 0, 'cheer': 1, 'cheered': 1, 'cheerer': 1, 'cheerful': 1, 'cheerfully': 1, 'cheerfulness': 1, 'cheerier': 1, 'cheeriest': 1, 'cheerily': 1, 'cheeriness': 1, 'cheering': 1, 'cheerio': 1, 'cheerlead': 1, 'cheerleader': 1, 'cheerleaders': 1, 'cheerleading': 1, 'cheerless': 0, 'cheers': 1, 'cheery': 1, 'cherish': 1, 'cherished': 1, 'cherishes': 1, 'cherishing': 1, 'chic': 1, 'childish': 0, 'chilling': 0, 'choke': 0, 'choked': 0, 'chokes': 0, 'choking': 0, 'chuckle': 1, 'chuckled': 1, 'chuckles': 1, 'chuckling': 1, 'clarifies': 1, 'clarity': 1, 'classy': 1, 'clean': 1, 'cleaner': 1, 'clear': 1, 'cleared': 1, 'clearly': 1, 'clears': 1, 'clever': 1, 'cleverer': 1, 'cleverest': 1, 'cleverly': 1, 'cleverness': 1, 'clouded': 0, 'clueless': 0, 'cock': 0, 'cocksucker': 0, 'cocksuckers': 0, 'cocky': 0, 'coerced': 0, 'collapse': 0, 'collapsed': 0, 'collapses': 0, 'collapsing': 0, 'collide': 0, 'collides': 0, 'colliding': 0, 'collision': 0, 'collisions': 0, 'colluding': 0, 'combat': 0, 'combats': 0, 'comedian': 1, 'comedians': 1, 'comedic': 1, 'comedienne': 1, 'comedies': 1, 'comedo': 1, 'comedown': 0, 'comedy': 1, 'comfort': 1, 'comfortable': 1, 'comfortably': 1, 'comforted': 1, 'comforter': 1, 'comforters': 1, 'comforting': 1, 'comforts': 1, 'commend': 1, 'commended': 1, 'commit': 1, 'commitment': 1, 'commitments': 1, 'commits': 1, 'committed': 1, 'committing': 1, 'compassion': 1, 'compassionate': 1, 'compassionately': 1, 'compelled': 1, 'compelling': 1, 'competent': 1, 'competitive': 1, 'complacent': 0, 'complain': 0, 'complainant': 0, 'complained': 0, 'complainer': 0, 'complainers': 0, 'complaining': 0, 'complains': 0, 'complaint': 0, 'complaints': 0, 'compliment': 1, 'complimentary': 1, 'complimented': 1, 'complimenting': 1, 'compliments': 1, 'comprehensive': 1, 'condemn': 0, 'condemnation': 0, 'condemned': 0, 'condemns': 0, 'confidence': 1, 'confident': 1, 'confidently': 1, 'conflict': 0, 'conflicting': 0, 'conflicts': 0, 'confront': 0, 'confrontation': 0, 'confrontational': 0, 'confrontations': 0, 'confronted': 0, 'confronting': 0, 'confronts': 0, 'confuse': 0, 'confused': 0, 'confuses': 0, 'confusing': 0, 'confusingly': 0, 'confusion': 0, 'confusions': 0, 'congrats': 1, 'congratulate': 1, 'congratulation': 1, 'congratulations': 1, 'consent': 1, 'consents': 1, 'considerate': 1, 'conspiracy': 0, 'constrained': 0, 'contagion': 0, 'contagious': 0, 'contempt': 0, 'contemptible': 0, 'contemptuous': 0, 'contend': 1, 'contender': 1, 'contented': 1, 'contentedly': 1, 'contentious': 0, 'contentment': 1, 'contradict': 0, 'contradicted': 0, 'contradicting': 0, 'contradiction': 0, 'contradictions': 0, 'contradictory': 0, 'contradicts': 0, 'controversial': 0, 'controversially': 0, 'convince': 1, 'convinced': 1, 'convinces': 1, 'convincing': 1, 'convincingly': 1, 'convivial': 1, 'cool': 1, 'cornered': 0, 'corpse': 0, 'costly': 0, 'courage': 1, 'courageous': 1, 'courageously': 1, 'courteous': 1, 'courtesy': 1, 'cover-up': 0, 'coward': 0, 'cowardly': 0, 'coziness': 1, 'cramp': 0, 'crap': 0, 'crappy': 0, 'crash': 0, 'craze': 0, 'crazed': 0, 'crazes': 1, 'crazier': 0, 'craziest': 0, 'crazily': 0, 'craziness': 0, 'crazing': 0, 'crazy': 0, 'create': 1, 'created': 1, 'creates': 1, 'creatin': 1, 'creatine': 1, 'creating': 1, 'creation': 1, 'creationism': 1, 'creationist': 1, 'creationists': 1, 'creations': 1, 'creative': 1, 'creatively': 1, 'creativeness': 1, 'creativity': 1, 'credit': 1, 'creditable': 1, 'credited': 1, 'crediting': 1, 'creditor': 0, 'credits': 1, 'crestfallen': 0, 'cried': 0, 'cries': 0, 'crime': 0, 'criminal': 0, 'criminals': 0, 'crisis': 0, 'critic': 0, 'critical': 0, 'criticise': 0, 'criticised': 0, 'criticises': 0, 'criticising': 0, 'criticism': 0, 'criticisms': 0, 'criticize': 0, 'criticized': 0, 'criticizes': 0, 'criticizing': 0, 'critics': 0, 'crude': 0, 'crudely': 0, 'cruel': 0, 'crueler': 0, 'cruelest': 0, 'cruellest': 0, 'cruelly': 0, 'cruelties': 0, 'cruelty': 0, 'crush': 0, 'crushed': 0, 'crushes': 0, 'crushing': 0, 'cry': 0, 'crying': 0, 'cunt': 0, 'cunts': 0, 'curious': 1, 'curse': 0, 'cut': 0, 'cute': 1, 'cutely': 1, 'cuteness': 1, 'cuter': 1, 'cutes': 1, 'cutest': 1, 'cutesy': 1, 'cutey': 1, 'cutie': 1, 'cutiepie': 1, 'cuties': 1, 'cuts': 0, 'cutting': 0, 'cynic': 0, 'cynical': 0, 'cynically': 0, 'cynicism': 0, 'cynics': 0, 'damage': 0, 'damaged': 0, 'damages': 0, 'damaging': 0, 'damn': 0, 'damnable': 0, 'damnation': 0, 'damned': 0, 'damnedest': 0, 'damning': 0, 'damnit': 0, 'damns': 0, 'danger': 0, 'dangerous': 0, 'dangerously': 0, 'dangers': 0, 'daredevil': 1, 'daring': 1, 'darkest': 0, 'darkness': 0, 'darling': 1, 'darlings': 1, 'dauntless': 1, 'daze': 0, 'dazed': 0, 'dead': 0, 'deadlock': 0, 'deafening': 0, 'dear': 1, 'dearer': 1, 'dearest': 1, 'dearie': 1, 'dearies': 1, 'dearly': 1, 'dears': 1, 'dearth': 0, 'deary': 1, 'death': 0, 'debonair': 1, 'debt': 0, 'decay': 0, 'decayed': 0, 'decaying': 0, 'decays': 0, 'deceit': 0, 'deceitful': 0, 'deceive': 0, 'deceived': 0, 'deceives': 0, 'deceiving': 0, 'deception': 0, 'decisive': 1, 'dedicated': 1, 'defeat': 0, 'defeated': 0, 'defeater': 0, 'defeating': 0, 'defeatist': 0, 'defeats': 0, 'defect': 0, 'defected': 0, 'defecting': 0, 'defection': 0, 'defections': 0, 'defective': 0, 'defector': 0, 'defectors': 0, 'defects': 0, 'defence': 1, 'defenceman': 1, 'defences': 0, 'defender': 1, 'defenders': 1, 'defense': 1, 'defenseless': 0, 'defenseman': 1, 'defensemen': 0, 'defenses': 1, 'defensible': 1, 'defensive': 1, 'defensively': 0, 'defensiveness': 0, 'defer': 0, 'deferring': 0, 'defiant': 0, 'deficit': 0, 'definite': 1, 'definitely': 1, 'degradation': 0, 'degrade': 0, 'degraded': 0, 'degrader': 0, 'degrades': 0, 'degrading': 0, 'dehumanize': 0, 'dehumanizing': 0, 'dejected': 0, 'delay': 0, 'delayed': 0, 'delectable': 1, 'delicate': 1, 'delicately': 1, 'delicates': 1, 'delicatessen': 1, 'delicious': 1, 'deliciously': 1, 'deliciousness': 1, 'delight': 1, 'delighted': 1, 'delightful': 1, 'delightfully': 1, 'delighting': 1, 'delights': 1, 'demand': 0, 'demanded': 0, 'demanding': 0, 'demonstration': 1, 'demoralized': 0, 'denied': 0, 'denier': 0, 'deniers': 0, 'denies': 0, 'denounce': 0, 'denounces': 0, 'deny': 0, 'denying': 0, 'depress': 0, 'depressant': 0, 'depressants': 0, 'depressed': 0, 'depresses': 0, 'depressing': 0, 'depressingly': 0, 'depression': 0, 'depressions': 0, 'depressive': 0, 'deprivation': 0, 'deprive': 0, 'deprived': 0, 'deprives': 0, 'depriving': 0, 'derail': 0, 'derailed': 0, 'derails': 0, 'deride': 0, 'derided': 0, 'derision': 0, 'desirable': 1, 'desire': 1, 'desired': 1, 'desirous': 1, 'despair': 0, 'despairing': 0, 'despairs': 0, 'desperate': 0, 'desperately': 0, 'desperation': 0, 'despise': 0, 'despised': 0, 'despises': 0, 'despising': 0, 'despondent': 0, 'destroy': 0, 'destroyed': 0, 'destroyer': 0, 'destroyers': 0, 'destroying': 0, 'destroys': 0, 'destruct': 0, 'destructed': 0, 'destructing': 0, 'destruction': 0, 'destructions': 0, 'destructive': 0, 'detached': 0, 'detain': 0, 'detained': 0, 'detention': 0, 'determinant': 1, 'determinate': 1, 'determination': 1, 'determinative': 1, 'determined': 1, 'devastate': 0, 'devastated': 0, 'devastates': 0, 'devastating': 0, 'devastatingly': 0, 'devastation': 0, 'devastator': 0, 'devil': 0, 'deviled': 0, 'devilish': 0, 'devilishly': 0, 'devils': 0, 'devote': 1, 'devoted': 1, 'devotee': 1, 'devotees': 1, 'devotes': 1, 'devoting': 1, 'devotion': 1, 'devotional': 1, 'devotionals': 1, 'devotions': 1, 'diamond': 1, 'dick': 0, 'dickhead': 0, 'die': 0, 'died': 0, 'difficult': 0, 'difficulties': 0, 'difficulty': 0, 'dignified': 1, 'dignify': 1, 'dignitaries': 1, 'dignitary': 1, 'dignity': 1, 'dilemma': 0, 'dipshit': 0, 'dire': 0, 'dirt': 0, 'dirtier': 0, 'dirtiest': 0, 'dirty': 0, 'disabling': 0, 'disadvantage': 0, 'disadvantaged': 0, 'disadvantages': 0, 'disagree': 0, 'disagreeable': 0, 'disagreed': 0, 'disagreeing': 0, 'disagreement': 0, 'disagreements': 0, 'disagrees': 0, 'disappear': 0, 'disappeared': 0, 'disappears': 0, 'disappoint': 0, 'disappointed': 0, 'disappointing': 0, 'disappointingly': 0, 'disappointment': 0, 'disappointments': 0, 'disappoints': 0, 'disaster': 0, 'disasters': 0, 'disastrous': 0, 'disbelieve': 0, 'discard': 0, 'discarded': 0, 'discarding': 0, 'discards': 0, 'discomfort': 0, 'discomforts': 0, 'discontented': 0, 'discord': 0, 'discounted': 1, 'discourage': 0, 'discouraged': 0, 'discouragement': 0, 'discourages': 0, 'discouraging': 0, 'discredited': 0, 'disdain': 0, 'disgrace': 0, 'disgraced': 0, 'disguise': 0, 'disguised': 0, 'disguises': 0, 'disguising': 0, 'disgust': 0, 'disgusted': 0, 'disgusting': 0, 'disgustingly': 0, 'disgusts': 0, 'disheartened': 0, 'disheartening': 0, 'dishonest': 0, 'disillusion': 0, 'disillusioned': 0, 'disillusionment': 0, 'disjointed': 0, 'dislike': 0, 'disliked': 0, 'dislikes': 0, 'disliking': 0, 'dismal': 0, 'dismay': 0, 'dismayed': 0, 'disorder': 0, 'disorganized': 0, 'disoriented': 0, 'disparage': 0, 'disparaging': 0, 'displeased': 0, 'dispute': 0, 'disputed': 0, 'disputes': 0, 'disputing': 0, 'disqualified': 0, 'disquiet': 0, 'disregard': 0, 'disregarded': 0, 'disregarding': 0, 'disregards': 0, 'disrespect': 0, 'disrespected': 0, 'disruption': 0, 'disruptions': 0, 'disruptive': 0, 'dissatisfaction': 0, 'dissatisfied': 0, 'distort': 0, 'distorted': 0, 'distorting': 0, 'distorts': 0, 'distract': 0, 'distracted': 0, 'distracting': 0, 'distraction': 0, 'distractions': 0, 'distracts': 0, 'distraught': 0, 'distress': 0, 'distressed': 0, 'distresses': 0, 'distressing': 0, 'distrust': 0, 'distrustful': 0, 'distrusting': 0, 'disturb': 0, 'disturbance': 0, 'disturbances': 0, 'disturbed': 0, 'disturber': 0, 'disturbing': 0, 'disturbingly': 0, 'disturbs': 0, 'dithering': 0, 'divination': 1, 'divine': 1, 'divinely': 1, 'diviners': 1, 'divines': 1, 'diving': 1, 'divinity': 1, 'dizzy': 0, 'dodging': 0, 'dodgy': 0, 'dominance': 1, 'dominate': 0, 'dominates': 1, 'dominating': 0, 'domination': 0, 'dominators': 0, 'dominatrix': 0, 'doom': 0, 'doomed': 0, 'dooms': 0, 'doomsday': 0, 'dork': 0, 'dorkiest': 0, 'dorks': 0, 'dorky': 0, 'doubt': 0, 'doubted': 0, 'doubter': 0, 'doubters': 0, 'doubtful': 0, 'doubting': 0, 'doubtless': 1, 'doubts': 0, 'douche': 0, 'douchebag': 0, 'downcast': 0, 'downhearted': 0, 'downside': 0, 'drag': 0, 'dragged': 0, 'drags': 0, 'drained': 0, 'dread': 0, 'dreaded': 0, 'dreadful': 0, 'dreadfully': 0, 'dreading': 0, 'dreadlock': 0, 'dreadlocks': 0, 'dreadnought': 0, 'dreads': 0, 'dream': 1, 'dreams': 1, 'dreary': 0, 'droopy': 0, 'drop': 0, 'drown': 0, 'drowned': 0, 'drowns': 0, 'drunk': 0, 'dubious': 0, 'dud': 0, 'dull': 0, 'dullard': 0, 'dulled': 0, 'duller': 0, 'dullest': 0, 'dulling': 0, 'dullness': 0, 'dulls': 0, 'dully': 0, 'dumb': 0, 'dumbass': 0, 'dumbbell': 0, 'dumbbells': 0, 'dumbed': 0, 'dumber': 0, 'dumbest': 0, 'dumbfounded': 0, 'dumbing': 0, 'dumbness': 0, 'dumbs': 0, 'dumbstruck': 0, 'dump': 0, 'dumped': 0, 'dumper': 0, 'dumping': 0, 'dumpling': 1, 'dumplings': 0, 'dumps': 0, 'dumpster': 0, 'dumpsters': 0, 'dumpy': 0, 'dupe': 0, 'duped': 0, 'dwell': 1, 'dweller': 1, 'dwellers': 0, 'dwelling': 1, 'dwells': 0, 'dynamic': 1, 'dynamically': 1, 'dynamics': 1, 'dynamism': 1, 'dynamite': 1, 'dynamites': 0, 'dynamos': 1, 'dysfunction': 0, 'eager': 1, 'eagerly': 1, 'eagerness': 1, 'earnest': 1, 'ease': 1, 'eased': 1, 'easel': 1, 'easement': 1, 'eases': 1, 'easier': 1, 'easiest': 1, 'easily': 1, 'easiness': 1, 'easing': 1, 'easy': 1, 'easygoing': 1, 'ecstacy': 1, 'ecstasy': 1, 'ecstatic': 1, 'eerie': 0, 'eery': 0, 'effective': 1, 'effectively': 1, 'efficiencies': 1, 'efficiency': 1, 'efficient': 1, 'efficiently': 1, 'effin': 0, 'egotism': 0, 'egotist': 0, 'egotistic': 0, 'egotistical': 0, 'elated': 1, 'elation': 1, 'elegance': 1, 'elegant': 1, 'elegantly': 1, 'embarrass': 0, 'embarrassed': 0, 'embarrasses': 0, 'embarrassing': 0, 'embarrassingly': 0, 'embarrassment': 0, 'embarrassments': 0, 'embittered': 0, 'embrace': 1, 'emergency': 0, 'emotional': 1, 'empathetic': 1, 'emptied': 0, 'emptier': 0, 'empties': 0, 'emptiest': 0, 'emptiness': 0, 'empty': 0, 'emptying': 0, 'enchanted': 1, 'encourage': 1, 'encouraged': 1, 'encouragement': 1, 'encouragements': 1, 'encourager': 1, 'encourages': 1, 'encouraging': 1, 'endorse': 1, 'endorsed': 1, 'endorsement': 1, 'endorses': 1, 'enemies': 0, 'enemy': 0, 'energetic': 1, 'energetically': 1, 'energetics': 1, 'energies': 1, 'energise': 1, 'energised': 1, 'energising': 1, 'energize': 1, 'energized': 1, 'energizer': 1, 'energizes': 1, 'energizing': 1, 'energy': 1, 'engage': 1, 'engaged': 1, 'engagement': 1, 'engagements': 1, 'engager': 1, 'engages': 1, 'engaging': 1, 'engrossed': 1, 'enjoy': 1, 'enjoyable': 1, 'enjoyed': 1, 'enjoying': 1, 'enjoyment': 1, 'enjoys': 1, 'enlighten': 1, 'enlightened': 1, 'enlightening': 1, 'enlightens': 1, 'ennui': 0, 'enrage': 0, 'enraged': 0, 'enrages': 0, 'enraging': 0, 'enslave': 0, 'enslaved': 0, 'enslaves': 0, 'ensure': 1, 'ensuring': 1, 'enterprising': 1, 'entertain': 1, 'entertained': 1, 'entertainer': 1, 'entertainers': 1, 'entertaining': 1, 'entertainment': 1, 'entertainments': 1, 'entertains': 1, 'enthused': 1, 'enthusiasm': 1, 'enthusiast': 1, 'enthusiastic': 1, 'enthusiastically': 1, 'enthusiasts': 1, 'entitled': 1, 'entrusted': 1, 'envied': 0, 'envier': 0, 'envies': 0, 'envious': 0, 'envy': 0, 'envying': 0, 'erroneous': 0, 'error': 0, 'errors': 0, 'escape': 1, 'escapes': 1, 'escaping': 1, 'esteemed': 1, 'ethical': 1, 'euphoria': 1, 'euphoric': 1, 'eviction': 0, 'evil': 0, 'evildoers': 0, 'evilest': 0, 'evilly': 0, 'evilness': 0, 'evils': 0, 'exaggerate': 0, 'exaggerated': 0, 'exaggerates': 0, 'exaggerating': 0, 'exasperated': 0, 'excel': 1, 'excelled': 1, 'excellence': 1, 'excellency': 1, 'excellent': 1, 'excellently': 1, 'excelling': 1, 'excels': 1, 'excelsior': 1, 'excitable': 1, 'excitant': 1, 'excitation': 1, 'excite': 1, 'excited': 1, 'excitedly': 1, 'excitement': 1, 'excitements': 1, 'exciter': 1, 'excites': 1, 'exciting': 1, 'excitingly': 1, 'exclude': 0, 'excluded': 0, 'exclusion': 0, 'exclusive': 1, 'excruciating': 0, 'excruciatingly': 0, 'excuse': 1, 'exempt': 1, 'exhaust': 0, 'exhausted': 0, 'exhausting': 0, 'exhaustion': 0, 'exhaustive': 0, 'exhausts': 0, 'exhilarated': 1, 'exhilarating': 1, 'exonerate': 1, 'exonerated': 1, 'expand': 1, 'expands': 1, 'expel': 0, 'expelled': 0, 'expelling': 0, 'expels': 0, 'exploit': 0, 'exploited': 0, 'exploiting': 0, 'exploits': 0, 'exploration': 1, 'explorations': 1, 'expose': 0, 'exposed': 0, 'exposes': 0, 'exposing': 0, 'extend': 1, 'extends': 1, 'exuberant': 1, 'fab': 1, 'fabulous': 1, 'fabulousness': 1, 'fad': 1, 'fag': 0, 'faggot': 0, 'faggots': 0, 'fail': 0, 'failed': 0, 'failing': 0, 'failings': 0, 'faille': 1, 'fails': 0, 'failure': 0, 'failures': 0, 'fair': 1, 'faith': 1, 'faithful': 1, 'faithfully': 1, 'faithfulness': 1, 'faithless': 0, 'faiths': 1, 'fake': 0, 'fakes': 0, 'faking': 0, 'fallen': 0, 'falling': 0, 'falsified': 0, 'falsify': 0, 'fame': 1, 'fan': 1, 'fantastic': 1, 'fantastical': 1, 'fantastico': 1, 'farce': 0, 'fascinate': 1, 'fascinated': 1, 'fascinates': 1, 'fascination': 1, 'fascinating': 1, 'fascist': 0, 'fascists': 0, 'fatal': 0, 'fatalistic': 0, 'fatalities': 0, 'fatality': 0, 'fatally': 0, 'fatigue': 0, 'fatigued': 0, 'fatigues': 0, 'fault': 0, 'faulted': 0, 'faultless': 1, 'faults': 0, 'faulty': 0, 'fave': 1, 'favor': 1, 'favorable': 1, 'favorably': 1, 'favored': 1, 'favoring': 1, 'favorite': 1, 'favorited': 1, 'favorites': 1, 'favoritism': 1, 'favors': 1, 'favour': 1, 'favoured': 1, 'favouring': 1, 'favours': 1, 'fear': 0, 'feared': 0, 'fearful': 0, 'fearfully': 0, 'fearing': 0, 'fearless': 1, 'fearlessly': 1, 'fearlessness': 1, 'fears': 0, 'fearsome': 0, 'feeble': 0, 'feeling': 1, 'felonies': 0, 'felony': 0, 'ferocious': 0, 'ferociously': 0, 'ferocity': 0, 'fervent': 1, 'festival': 1, 'festivals': 1, 'festive': 1, 'festivities': 1, 'festivity': 1, 'feud': 0, 'feudal': 0, 'feudalism': 0, 'feuding': 0, 'feuds': 0, 'fiasco': 0, 'fidgety': 0, 'fiery': 0, 'fiesta': 1, 'fiestas': 1, 'fight': 0, 'fighter': 1, 'fighters': 0, 'fighting': 0, 'fightings': 0, 'fights': 0, 'fine': 1, 'fire': 0, 'fired': 0, 'firing': 0, 'fit': 1, 'fitness': 1, 'flagship': 1, 'flatter': 1, 'flattered': 1, 'flatterer': 0, 'flatterers': 1, 'flattering': 1, 'flatters': 1, 'flattery': 1, 'flawed': 0, 'flawless': 1, 'flawlessly': 1, 'flees': 0, 'flexibility': 1, 'flexible': 1, 'flirtation': 1, 'flirtatious': 1, 'flirted': 0, 'flirter': 0, 'flirting': 1, 'flirts': 1, 'flirty': 1, 'flop': 0, 'flops': 0, 'flu': 0, 'flunk': 0, 'flunked': 0, 'flunkies': 0, 'flunking': 0, 'flunky': 0, 'flustered': 0, 'focused': 1, 'foe': 0, 'foes': 0, 'foetal': 0, 'foetus': 1, 'fond': 1, 'fondly': 1, 'fondness': 1, 'fool': 0, 'fooled': 0, 'foolery': 0, 'fooling': 0, 'foolish': 0, 'foolishly': 0, 'foolishness': 0, 'foolproof': 1, 'fools': 0, 'forbid': 0, 'forbidden': 0, 'forbidding': 0, 'forbids': 0, 'forced': 0, 'foreclosure': 0, 'foreclosures': 0, 'forgave': 1, 'forget': 0, 'forgetful': 0, 'forgivable': 1, 'forgive': 1, 'forgiven': 1, 'forgiveness': 1, 'forgiver': 1, 'forgivers': 1, 'forgives': 1, 'forgiving': 1, 'forgotten': 0, 'fortunate': 1, 'fought': 0, 'frantic': 0, 'frantically': 0, 'fraud': 0, 'frauds': 0, 'fraudster': 0, 'fraudsters': 0, 'fraudulent': 0, 'freak': 0, 'freaked': 0, 'freakier': 0, 'freakiest': 0, 'freakiness': 0, 'freaking': 0, 'freakish': 0, 'freakishly': 0, 'freakout': 0, 'freaks': 0, 'freaky': 0, 'free': 1, 'freebase': 0, 'freebee': 1, 'freebie': 1, 'freebies': 1, 'freeborn': 1, 'freed': 1, 'freedman': 1, 'freedom': 1, 'freedoms': 1, 'freeform': 1, 'freehand': 1, 'freehold': 1, 'freeing': 1, 'freelance': 1, 'freelancer': 1, 'freelancers': 1, 'freelancing': 1, 'freeload': 0, 'freeloader': 0, 'freeloaders': 0, 'freeloading': 0, 'freely': 1, 'freeman': 1, 'freemasonry': 1, 'freemen': 1, 'freer': 1, 'frees': 1, 'freesia': 1, 'freest': 1, 'freestanding': 1, 'freestyle': 1, 'freestyler': 1, 'freestylers': 1, 'freestyles': 1, 'freethinker': 1, 'freeware': 1, 'freeway': 1, 'freewheel': 1, 'freewheeling': 1, 'freewill': 1, 'freeze': 1, 'freezers': 0, 'freezes': 0, 'freezing': 0, 'frenzy': 0, 'fresh': 1, 'friend': 1, 'friended': 1, 'friending': 1, 'friendless': 0, 'friendlier': 1, 'friendlies': 1, 'friendliest': 1, 'friendliness': 1, 'friendly': 1, 'friends': 1, 'friendship': 1, 'friendships': 1, 'fright': 0, 'frighten': 0, 'frightened': 0, 'frightening': 0, 'frighteningly': 0, 'frightens': 0, 'frightful': 0, 'frightfully': 0, 'frights': 0, 'frisky': 1, 'frowning': 0, 'frustrate': 0, 'frustrated': 0, 'frustrates': 0, 'frustrating': 0, 'frustratingly': 0, 'frustration': 0, 'frustrations': 0, 'fuck': 0, 'fucked': 0, 'fucker': 0, 'fuckers': 0, 'fuckface': 0, 'fuckhead': 0, 'fucks': 0, 'fucktard': 0, 'fud': 0, 'fuked': 0, 'fuking': 0, 'fulfill': 1, 'fulfilled': 1, 'fulfills': 1, 'fume': 0, 'fumer': 1, 'fumes': 0, 'fumette': 0, 'fuming': 0, 'fun': 1, 'funeral': 0, 'funerals': 0, 'funky': 0, 'funnel': 1, 'funneled': 1, 'funneling': 0, 'funnels': 1, 'funner': 1, 'funnest': 1, 'funnier': 1, 'funnies': 1, 'funniest': 1, 'funnily': 1, 'funniness': 1, 'funny': 1, 'funnyman': 1, 'furious': 0, 'furiously': 0, 'fury': 0, 'futile': 0, 'gag': 0, 'gagged': 0, 'gain': 1, 'gained': 1, 'gaining': 1, 'gains': 1, 'gallant': 1, 'gallantry': 1, 'geek': 0, 'geekiest': 0, 'geeks': 0, 'geeky': 0, 'generosity': 1, 'generous': 1, 'generously': 1, 'genial': 1, 'gentle': 1, 'gentler': 1, 'gentlest': 1, 'gently': 1, 'ghost': 0, 'giddy': 0, 'gift': 1, 'giggle': 1, 'giggled': 1, 'giggles': 1, 'giggling': 1, 'giggly': 1, 'giver': 1, 'givers': 1, 'giving': 1, 'glad': 1, 'gladly': 1, 'glamor': 1, 'glamorize': 1, 'glamorizing': 1, 'glamorous': 1, 'glamour': 1, 'glamourous': 1, 'glamours': 1, 'glee': 1, 'gleeful': 1, 'gloom': 0, 'gloomy': 0, 'glories': 1, 'glorification': 1, 'glorified': 1, 'glorifies': 1, 'glorify': 1, 'glorifying': 1, 'glorious': 1, 'gloriously': 1, 'glory': 1, 'glum': 0, 'god': 1, 'goddam': 0, 'goddamn': 0, 'goddamned': 0, 'godsend': 1, 'good': 1, 'goodness': 1, 'gorgeous': 1, 'gorgeously': 1, 'gorgeousness': 1, 'gossip': 0, 'gossiped': 0, 'gossiper': 0, 'gossipers': 0, 'gossiping': 0, 'gossips': 0, 'gossipy': 0, 'grace': 1, 'graced': 1, 'graceful': 1, 'gracefully': 1, 'graces': 1, 'gracing': 1, 'gracioso': 1, 'gracious': 1, 'graciously': 1, 'graciousness': 1, 'grand': 1, 'grandee': 1, 'grandees': 1, 'grander': 1, 'grandest': 1, 'grandeur': 1, 'grant': 1, 'granted': 1, 'granting': 1, 'grants': 1, 'grateful': 1, 'gratefully': 1, 'gratefulness': 1, 'gratification': 1, 'gratified': 1, 'gratify': 1, 'gratifying': 1, 'gratin': 1, 'grating': 0, 'gratis': 1, 'gratitude': 1, 'gratz': 1, 'grave': 0, 'gravel': 0, 'gravelly': 0, 'gravely': 0, 'graven': 0, 'graver': 0, 'graves': 0, 'gravestone': 0, 'gravestones': 0, 'graveyard': 0, 'graveyards': 0, 'great': 1, 'greater': 1, 'greatest': 1, 'greed': 0, 'greediest': 0, 'greedily': 0, 'greediness': 0, 'greedy': 0, 'greenwash': 0, 'greenwashing': 0, 'greet': 1, 'greeted': 1, 'greeting': 1, 'greetings': 1, 'greets': 1, 'grey': 1, 'grief': 0, 'grievance': 0, 'grievances': 0, 'grieve': 0, 'grieved': 0, 'grieves': 0, 'grieving': 0, 'grievous': 0, 'grim': 0, 'grimace': 0, 'grimaces': 0, 'grimacing': 0, 'grime': 0, 'grimes': 0, 'grimiest': 0, 'grimly': 0, 'grimmer': 0, 'grimmest': 0, 'grimy': 0, 'grin': 1, 'grinned': 1, 'grinner': 1, 'grinning': 1, 'grins': 1, 'gross': 0, 'grossed': 0, 'grosser': 0, 'grosses': 0, 'grossest': 0, 'grossing': 0, 'grossly': 0, 'grossness': 0, 'grouch': 0, 'grouchy': 0, 'growing': 1, 'growth': 1, 'guarantee': 1, 'guilt': 0, 'guiltless': 1, 'guilts': 0, 'guilty': 0, 'gullibility': 0, 'gullible': 0, 'gun': 0, 'ha': 1, 'hacked': 0, 'haha': 1, 'hahaha': 1, 'hahas': 1, 'hail': 1, 'hailed': 1, 'hallelujah': 1, 'handsome': 1, 'handsomely': 1, 'handsomeness': 1, 'handsomer': 1, 'handsomest': 1, 'hapless': 0, 'happier': 1, 'happiest': 1, 'happily': 1, 'happiness': 1, 'happing': 1, 'happy': 1, 'harass': 0, 'harassed': 0, 'harasser': 0, 'harassers': 0, 'harasses': 0, 'harassing': 0, 'harassment': 0, 'hard': 0, 'hardship': 0, 'hardy': 1, 'harm': 0, 'harmed': 0, 'harming': 0, 'harmless': 1, 'harmlessly': 1, 'harmonic': 1, 'harmonica': 1, 'harmonicas': 1, 'harmonics': 1, 'harmonies': 1, 'harmonious': 1, 'harmoniously': 1, 'harmonise': 1, 'harmonising': 1, 'harmonium': 1, 'harmonization': 1, 'harmonize': 1, 'harmonized': 1, 'harmonizer': 1, 'harmonizers': 1, 'harmonizes': 1, 'harmonizing': 1, 'harmony': 1, 'harms': 0, 'harsh': 0, 'harsher': 0, 'harshest': 0, 'hate': 0, 'hated': 0, 'hateful': 0, 'hatefulness': 0, 'hater': 0, 'haters': 0, 'hates': 0, 'hating': 0, 'hatred': 0, 'haunt': 0, 'haunted': 0, 'haunting': 0, 'haunts': 0, 'havoc': 0, 'healthy': 1, 'heartbreak': 0, 'heartbreaker': 0, 'heartbreakers': 0, 'heartbreaking': 0, 'heartbreakingly': 0, 'heartbreaks': 0, 'heartbroken': 0, 'heartfelt': 1, 'heartless': 0, 'heartwarming': 1, 'heaven': 1, 'heavenly': 1, 'heavens': 1, 'heh': 0, 'hell': 0, 'hellish': 0, 'help': 1, 'helper': 1, 'helpers': 1, 'helpful': 1, 'helpfully': 1, 'helpfulness': 1, 'helping': 1, 'helpless': 0, 'helplessly': 0, 'helplessness': 0, 'helps': 1, 'hero': 1, 'heroes': 1, 'heroic': 1, 'heroically': 1, 'heroics': 1, 'heroin': 0, 'heroine': 1, 'heroines': 1, 'heroism': 1, 'heron': 1, 'herons': 1, 'heros': 1, 'hesitancy': 0, 'hesitant': 0, 'hesitantly': 0, 'hesitate': 0, 'hesitated': 0, 'hesitates': 0, 'hesitating': 0, 'hesitation': 0, 'hesitations': 0, 'hid': 0, 'hide': 0, 'hides': 0, 'hiding': 0, 'highlight': 1, 'hilarious': 1, 'hindrance': 0, 'hoax': 0, 'holiday': 1, 'holidays': 1, 'homesick': 0, 'homesickness': 0, 'honest': 1, 'honestly': 1, 'honesty': 1, 'honor': 1, 'honorable': 1, 'honorably': 1, 'honorary': 1, 'honored': 1, 'honoree': 1, 'honorees': 1, 'honorer': 1, 'honoring': 1, 'honors': 1, 'honour': 1, 'honourable': 1, 'honoured': 1, 'honouring': 1, 'honours': 1, 'hooligan': 0, 'hooliganism': 0, 'hooligans': 0, 'hooray': 1, 'hope': 1, 'hoped': 1, 'hopeful': 1, 'hopefully': 1, 'hopeless': 0, 'hopelessly': 0, 'hopelessness': 0, 'hopes': 1, 'hoping': 1, 'horrendous': 0, 'horrendously': 0, 'horrible': 0, 'horribleness': 0, 'horribles': 0, 'horribly': 0, 'horrid': 0, 'horrific': 0, 'horrifically': 0, 'horrified': 0, 'horrifies': 0, 'horrify': 0, 'horrifying': 0, 'horrifyingly': 0, 'horror': 0, 'horrors': 0, 'hostile': 0, 'hostiles': 0, 'hostilities': 0, 'hostility': 0, 'hug': 1, 'huge': 1, 'huggable': 1, 'hugged': 1, 'hugger': 1, 'huggers': 1, 'hugging': 1, 'hugs': 1, 'humerous': 1, 'humiliate': 0, 'humiliated': 0, 'humiliates': 0, 'humiliating': 0, 'humiliation': 0, 'humor': 1, 'humored': 1, 'humorist': 1, 'humorless': 0, 'humorous': 1, 'humorously': 1, 'humors': 1, 'humour': 1, 'humourous': 1, 'hunger': 0, 'hurrah': 1, 'hurray': 1, 'hurt': 0, 'hurtful': 0, 'hurting': 0, 'hurtle': 0, 'hurtles': 0, 'hurtling': 0, 'hurts': 0, 'hypocritical': 0, 'hysteria': 0, 'hysterical': 0, 'hysterics': 0, 'ideal': 1, 'idealism': 1, 'idealist': 1, 'idealistic': 1, 'idealists': 1, 'idealize': 1, 'idealized': 1, 'idealizing': 1, 'ideally': 1, 'ideals': 1, 'idiot': 0, 'idiotic': 0, 'ignoramus': 0, 'ignorance': 0, 'ignorant': 0, 'ignorantly': 0, 'ignore': 0, 'ignored': 0, 'ignorer': 0, 'ignores': 0, 'ignoring': 0, 'ill': 0, 'illegal': 0, 'illiteracy': 0, 'illness': 0, 'illnesses': 0, 'imbecile': 0, 'immobilized': 0, 'immoral': 0, 'immorality': 0, 'immortal': 1, 'immune': 1, 'impatience': 0, 'impatient': 0, 'impatiently': 0, 'imperfect': 0, 'impersonal': 0, 'impolite': 0, 'importance': 1, 'important': 1, 'importantly': 1, 'impose': 0, 'imposed': 0, 'imposes': 0, 'imposing': 0, 'impotent': 0, 'impress': 1, 'impressed': 1, 'impresses': 1, 'impressing': 1, 'impression': 1, 'impressionable': 1, 'impressionism': 1, 'impressionist': 1, 'impressions': 1, 'impressive': 1, 'impressively': 1, 'imprisoned': 0, 'improve': 1, 'improved': 1, 'improvement': 1, 'improvements': 1, 'improves': 1, 'improving': 1, 'inability': 0, 'inaction': 0, 'inadequacies': 0, 'inadequacy': 0, 'inadequate': 0, 'incapable': 0, 'incapacitated': 0, 'incensed': 0, 'incentive': 1, 'incentives': 1, 'incompetence': 0, 'incompetent': 0, 'inconsiderate': 0, 'inconvenience': 0, 'inconvenient': 0, 'increase': 1, 'increased': 1, 'indecision': 0, 'indecisive': 0, 'indecisiveness': 0, 'indestructible': 1, 'indifference': 0, 'indifferent': 0, 'indignant': 0, 'indignation': 0, 'indoctrinate': 0, 'indoctrinated': 0, 'ineffective': 0, 'ineffectual': 0, 'infatuated': 1, 'infatuation': 1, 'infected': 0, 'inferior': 0, 'inferiority': 0, 'inferiors': 0, 'inflamed': 0, 'influential': 1, 'infringement': 0, 'infuriate': 0, 'infuriated': 0, 'infuriates': 0, 'infuriating': 0, 'inhibit': 0, 'inhibited': 0, 'inhibiting': 0, 'inhibition': 0, 'inhibitions': 0, 'inhibitor': 0, 'inhibitors': 0, 'inhibits': 0, 'injured': 0, 'injury': 0, 'injustice': 0, 'innocence': 1, 'innocent': 1, 'innocently': 1, 'innocents': 1, 'innovate': 1, 'innovates': 1, 'innovation': 1, 'innovative': 1, 'inquisition': 0, 'inquisitive': 1, 'insane': 0, 'insanity': 0, 'insecure': 0, 'insecurities': 0, 'insecurity': 0, 'insensitive': 0, 'insensitivity': 0, 'insignificant': 0, 'insincere': 0, 'insincerity': 0, 'insipid': 0, 'inspiration': 1, 'inspirational': 1, 'inspirations': 1, 'inspirator': 1, 'inspire': 1, 'inspired': 1, 'inspirer': 1, 'inspires': 1, 'inspiring': 1, 'inspirit': 1, 'inspirits': 1, 'insult': 0, 'insulted': 0, 'insulter': 0, 'insulting': 0, 'insults': 0, 'intact': 1, 'integrity': 1, 'intellect': 1, 'intellects': 1, 'intellectual': 1, 'intellectualism': 1, 'intellectualize': 1, 'intellectually': 1, 'intellectuals': 1, 'intelligence': 1, 'intelligencer': 1, 'intelligences': 1, 'intelligent': 1, 'intelligently': 1, 'intelligentsia': 1, 'intelligible': 1, 'intense': 1, 'interest': 1, 'interested': 1, 'interesting': 1, 'interestingly': 1, 'interests': 1, 'interrogated': 0, 'interrupt': 0, 'interrupted': 0, 'interrupting': 0, 'interruption': 0, 'interruptions': 0, 'interruptor': 0, 'interrupts': 0, 'intimidate': 0, 'intimidated': 0, 'intimidates': 0, 'intimidating': 0, 'intimidation': 0, 'intimidator': 0, 'intricate': 1, 'intrigues': 1, 'invigorate': 1, 'invigorated': 1, 'invigorating': 1, 'invincible': 1, 'invite': 1, 'inviting': 1, 'invulnerable': 1, 'irate': 0, 'ironic': 0, 'irony': 0, 'irrational': 0, 'irrationality': 0, 'irrationally': 0, 'irresistible': 1, 'irresponsible': 0, 'irreversible': 0, 'irritability': 0, 'irritable': 0, 'irritant': 0, 'irritants': 0, 'irritate': 0, 'irritated': 0, 'irritates': 0, 'irritating': 0, 'irritatingly': 0, 'irritation': 0, 'irritations': 0, 'isolate': 0, 'isolated': 0, 'isolates': 0, 'isolation': 0, 'isolator': 0, 'itchy': 0, 'jackass': 0, 'jackasses': 0, 'jaded': 0, 'jailed': 0, 'jaunty': 1, 'jealous': 0, 'jealousies': 0, 'jealously': 0, 'jealousy': 0, 'jeopardy': 0, 'jerk': 0, 'jerked': 0, 'jerks': 0, 'jewel': 1, 'jewels': 1, 'join': 1, 'joke': 1, 'joked': 1, 'joker': 1, 'jokes': 1, 'jokester': 1, 'jokesters': 1, 'jokey': 1, 'joking': 1, 'jollies': 1, 'jolly': 1, 'jovial': 1, 'joy': 1, 'joyed': 1, 'joyful': 1, 'joyfully': 1, 'joyfulness': 1, 'joyless': 0, 'joyous': 1, 'joyously': 1, 'joyride': 1, 'joyrides': 1, 'joyriding': 1, 'joys': 1, 'joystick': 1, 'joysticks': 1, 'jubilant': 1, 'jumpy': 0, 'justice': 1, 'justifiably': 1, 'justified': 1, 'keen': 1, 'keener': 1, 'keenest': 1, 'keenly': 1, 'keens': 1, 'kewl': 1, 'kidding': 1, 'kill': 0, 'killed': 0, 'killer': 0, 'killers': 0, 'killie': 0, 'killing': 0, 'killingly': 0, 'killings': 0, 'killjoy': 0, 'killjoys': 0, 'kills': 0, 'kind': 1, 'kinder': 1, 'kindly': 1, 'kindness': 1, 'kindnesses': 1, 'kiss': 1, 'kissable': 1, 'kissed': 1, 'kisser': 1, 'kissers': 1, 'kisses': 1, 'kissing': 1, 'kissy': 1, 'kudos': 1, 'lack': 0, 'lackadaisical': 0, 'lag': 0, 'lagged': 0, 'lagging': 0, 'lags': 0, 'laidback': 1, 'lame': 0, 'lameness': 0, 'lament': 0, 'lamentable': 0, 'lamentation': 0, 'lamentations': 0, 'lamented': 0, 'lamenter': 0, 'lamenting': 0, 'laments': 0, 'lamer': 0, 'lames': 0, 'lamest': 0, 'landmark': 1, 'laugh': 1, 'laughable': 1, 'laughably': 1, 'laughed': 1, 'laugher': 1, 'laughing': 1, 'laughs': 1, 'laughter': 1, 'laughters': 1, 'launched': 1, 'lawl': 1, 'lawsuit': 0, 'lawsuits': 0, 'lazier': 0, 'laziest': 0, 'lazy': 0, 'leak': 0, 'leaked': 0, 'leave': 0, 'leet': 1, 'legal': 1, 'legally': 1, 'lenient': 1, 'lethargic': 0, 'lethargy': 0, 'liabilities': 0, 'liability': 0, 'liar': 0, 'liars': 0, 'libelous': 0, 'libertarian': 1, 'libertarianism': 1, 'libertarians': 1, 'liberties': 1, 'libertine': 0, 'libertines': 1, 'liberty': 1, 'lied': 0, 'lies': 0, 'lifesaver': 1, 'lighthearted': 1, 'like': 1, 'likeable': 1, 'liked': 1, 'likes': 1, 'liking': 1, 'limitation': 0, 'limited': 0, 'litigation': 0, 'livelier': 1, 'livelihood': 1, 'livelihoods': 1, 'liveliness': 1, 'lively': 1, 'livid': 0, 'loathe': 0, 'loathed': 0, 'loathes': 0, 'loathing': 0, 'lobby': 1, 'lobbying': 0, 'lone': 0, 'lonelier': 0, 'loneliest': 0, 'loneliness': 0, 'lonely': 0, 'loner': 0, 'loners': 0, 'lonesome': 0, 'longing': 0, 'longingly': 1, 'longings': 1, 'loom': 0, 'loomed': 0, 'looming': 0, 'looms': 0, 'loose': 0, 'looses': 0, 'lose': 0, 'loser': 0, 'losers': 0, 'loses': 0, 'losing': 0, 'loss': 0, 'losses': 0, 'lossy': 0, 'lost': 0, 'louse': 0, 'lousy': 0, 'lovable': 1, 'love': 1, 'loved': 1, 'lovelies': 1, 'lovely': 1, 'lover': 1, 'loverly': 1, 'lovers': 1, 'loves': 1, 'loving': 1, 'lovingly': 1, 'low': 0, 'lowball': 0, 'lowbrow': 0, 'lowdown': 0, 'lowe': 1, 'lower': 0, 'lowercase': 1, 'lowered': 0, 'lowering': 0, 'lowers': 0, 'lowery': 0, 'lowest': 0, 'lowing': 0, 'lowland': 0, 'lowlands': 0, 'lowlife': 0, 'lowlifes': 0, 'lowlight': 0, 'lowlights': 0, 'lowly': 0, 'lown': 1, 'lowrider': 0, 'lows': 0, 'loyal': 1, 'loyalist': 1, 'loyalists': 1, 'loyally': 1, 'loyalties': 1, 'loyalty': 1, 'luck': 1, 'lucked': 1, 'luckie': 1, 'luckier': 1, 'luckiest': 1, 'luckily': 1, 'lucking': 1, 'luckless': 0, 'lucks': 1, 'lucky': 1, 'ludicrous': 0, 'ludicrously': 0, 'lulz': 1, 'lunatic': 0, 'lunatics': 0, 'lurk': 0, 'lurking': 0, 'lurks': 0, 'lying': 0, 'mad': 0, 'maddening': 0, 'madder': 0, 'maddest': 0, 'madly': 0, 'madness': 0, 'magnific': 1, 'magnification': 1, 'magnificence': 1, 'magnificent': 1, 'magnificently': 1, 'magnifico': 1, 'mandatory': 1, 'maniac': 0, 'maniacal': 0, 'maniacally': 0, 'maniacs': 0, 'manipulated': 0, 'manipulating': 0, 'manipulation': 0, 'marvel': 1, 'marvelous': 1, 'marvels': 1, 'masochism': 0, 'masochist': 0, 'masochistic': 0, 'masochists': 0, 'masterpiece': 1, 'masterpieces': 1, 'matter': 1, 'matters': 1, 'mature': 1, 'meaningful': 1, 'meaningless': 0, 'medal': 1, 'mediocrity': 0, 'meditative': 1, 'meh': 0, 'melancholia': 0, 'melancholic': 0, 'melancholy': 0, 'menace': 0, 'mercy': 1, 'merit': 1, 'merited': 1, 'meritocracy': 1, 'meritorious': 1, 'merits': 1, 'merrier': 1, 'merriest': 1, 'merrily': 1, 'merriment': 1, 'merry': 1, 'mess': 0, 'messed': 0, 'messy': 0, 'methodical': 1, 'mindless': 0, 'miracle': 1, 'mirth': 1, 'misbehave': 0, 'misbehaved': 0, 'misbehaves': 0, 'misbehaving': 0, 'mischief': 0, 'miser': 0, 'miserable': 0, 'miserably': 0, 'miserere': 0, 'miseries': 0, 'miserly': 0, 'misery': 0, 'misinformation': 0, 'misinformed': 0, 'misinterpreted': 0, 'misleading': 0, 'misread': 0, 'misrepresentation': 0, 'miss': 0, 'missed': 0, 'misses': 0, 'missing': 0, 'mistake': 0, 'mistaken': 0, 'mistakenly': 0, 'mistakes': 0, 'mistaking': 0, 'misunderstand': 0, 'misunderstanding': 0, 'misunderstands': 0, 'misunderstood': 0, 'mlm': 0, 'mmk': 1, 'moan': 0, 'moaned': 0, 'moaning': 0, 'moans': 0, 'mock': 0, 'mocked': 0, 'mocker': 0, 'mockers': 0, 'mockery': 0, 'mocking': 0, 'mocks': 0, 'molest': 0, 'molestation': 0, 'molested': 0, 'molester': 0, 'molesters': 0, 'molesting': 0, 'molests': 0, 'mongering': 0, 'monopolize': 0, 'mooch': 0, 'moocher': 0, 'moochers': 0, 'mooches': 0, 'mooching': 0, 'moodier': 0, 'moodiest': 0, 'moodiness': 0, 'moody': 0, 'mope': 0, 'moping': 0, 'moron': 0, 'moronic': 0, 'morons': 0, 'motherfucker': 0, 'motherfucking': 0, 'motivate': 1, 'motivated': 1, 'motivating': 1, 'motivation': 1, 'mourn': 0, 'mourned': 0, 'mourner': 0, 'mourners': 0, 'mournful': 0, 'mourning': 0, 'mourns': 0, 'murder': 0, 'murdered': 0, 'murderer': 0, 'murderers': 0, 'murdering': 0, 'murderous': 0, 'murders': 0, 'nag': 0, 'nagana': 0, 'nagged': 0, 'nagger': 0, 'naggers': 0, 'nagging': 0, 'naggy': 0, 'nags': 0, 'nah': 0, 'naive': 0, 'nastic': 1, 'nastier': 0, 'nasties': 0, 'nastiest': 0, 'nastiness': 0, 'nasty': 0, 'natural': 1, 'neat': 1, 'neater': 1, 'neatest': 1, 'neath': 1, 'neatly': 1, 'neatness': 1, 'needy': 0, 'negative': 0, 'negativity': 0, 'neglect': 0, 'neglected': 0, 'neglectful': 0, 'neglecting': 0, 'neglects': 0, 'nerd': 0, 'nerdier': 0, 'nerdiest': 1, 'nerdy': 0, 'nerves': 0, 'nervous': 0, 'nervously': 0, 'nervousness': 0, 'neurotic': 0, 'nice': 1, 'nicely': 1, 'niceness': 1, 'nicer': 1, 'nicest': 1, 'niceties': 1, 'nifty': 1, 'niggas': 0, 'nigger': 0, 'no': 0, 'noble': 1, 'noisy': 0, 'nonsense': 0, 'noob': 0, 'nosey': 0, 'notorious': 0, 'novel': 1, 'numb': 0, 'numbed': 0, 'number': 1, 'numbing': 0, 'numbingly': 0, 'numbness': 0, 'numbs': 0, 'numbskull': 0, 'nurture': 1, 'nurtured': 1, 'nurturer': 1, 'nurtures': 1, 'nurturing': 1, 'nuts': 0, 'obliterate': 0, 'obliterated': 0, 'obnoxious': 0, 'obnoxiously': 0, 'obnoxiousness': 0, 'obscene': 0, 'obsess': 0, 'obsessed': 0, 'obsesses': 0, 'obsessing': 0, 'obsession': 0, 'obsessions': 0, 'obsessive': 0, 'obsessively': 0, 'obsolete': 0, 'obstacle': 0, 'obstacles': 0, 'obstinate': 0, 'odd': 0, 'offence': 0, 'offences': 0, 'offend': 0, 'offended': 0, 'offender': 0, 'offenders': 0, 'offending': 0, 'offends': 0, 'offense': 0, 'offenses': 0, 'offensive': 0, 'offensively': 0, 'offline': 0, 'okay': 1, 'okays': 1, 'ominous': 0, 'once-in-a-lifetime': 1, 'openness': 1, 'opportune': 1, 'opportunism': 1, 'opportunist': 1, 'opportunistic': 0, 'opportunists': 1, 'opportunities': 1, 'opportunity': 1, 'oppressed': 0, 'oppressive': 0, 'optimal': 1, 'optimisation': 1, 'optimise': 1, 'optimised': 1, 'optimising': 1, 'optimism': 1, 'optimist': 1, 'optimistic': 1, 'optimistically': 1, 'optimists': 1, 'optimization': 1, 'optimize': 1, 'optimized': 1, 'optimizer': 1, 'optimizes': 1, 'optimizing': 1, 'original': 1, 'outcry': 0, 'outgoing': 1, 'outrage': 0, 'outraged': 0, 'outrageous': 0, 'outrageously': 0, 'outrages': 0, 'outraging': 0, 'outreach': 1, 'outstanding': 1, 'overjoyed': 1, 'overload': 0, 'overlooked': 0, 'overreact': 0, 'overreacted': 0, 'overreaction': 0, 'overreacts': 0, 'oversimplification': 1, 'oversimplify': 0, 'overstatement': 0, 'overweight': 0, 'overwhelm': 0, 'overwhelmed': 1, 'overwhelmingly': 0, 'overwhelms': 0, 'oxymoron': 0, 'pain': 0, 'pained': 0, 'painful': 0, 'painfully': 0, 'paining': 0, 'painless': 1, 'painlessly': 1, 'pains': 0, 'palatable': 1, 'panic': 0, 'panicked': 0, 'panicking': 0, 'panicky': 0, 'panics': 0, 'paradise': 1, 'paradox': 0, 'paranoia': 0, 'paranoiac': 0, 'paranoias': 0, 'paranoid': 0, 'pardon': 1, 'pardoned': 1, 'pardoning': 1, 'pardons': 1, 'parley': 0, 'partied': 1, 'partier': 1, 'partiers': 1, 'parties': 1, 'party': 1, 'partying': 1, 'passion': 1, 'passional': 1, 'passionate': 1, 'passionately': 1, 'passionless': 0, 'passions': 1, 'passive': 1, 'passively': 0, 'pathetic': 0, 'pathetically': 0, 'pay': 0, 'peace': 1, 'peaceable': 1, 'peaceably': 1, 'peaceful': 1, 'peacefully': 1, 'peacefulness': 1, 'peacekeeper': 1, 'peacekeepers': 1, 'peacekeeping': 1, 'peacemaker': 1, 'peacemakers': 1, 'peacemaking': 1, 'peaces': 1, 'peacetime': 1, 'peculiar': 1, 'peculiarity': 1, 'penalty': 0, 'pensive': 1, 'perfect': 1, 'perfecta': 1, 'perfectas': 1, 'perfected': 1, 'perfecter': 1, 'perfectest': 1, 'perfecting': 1, 'perfection': 1, 'perfectionism': 1, 'perfectionist': 1, 'perfectionists': 1, 'perfections': 1, 'perfectly': 1, 'perfectness': 1, 'perfecto': 1, 'perfects': 1, 'peril': 0, 'perjury': 0, 'perpetrator': 0, 'perpetrators': 0, 'perplexed': 0, 'persecute': 0, 'persecuted': 0, 'persecuting': 0, 'perturbed': 0, 'perverse': 0, 'perversion': 0, 'perversions': 0, 'perversity': 0, 'pervert': 0, 'perverted': 0, 'perverting': 0, 'perverts': 0, 'pesky': 0, 'pessimism': 0, 'pessimist': 0, 'pessimistic': 0, 'pessimists': 0, 'petrified': 0, 'petrifying': 0, 'pettiest': 0, 'petty': 0, 'phobia': 0, 'phobias': 0, 'phobic': 0, 'picturesque': 1, 'pileup': 0, 'pique': 0, 'piqued': 1, 'piss': 0, 'pissant': 0, 'pissed': 0, 'pisser': 0, 'pisses': 0, 'pissing': 0, 'pitiable': 0, 'pitied': 0, 'pitier': 0, 'pities': 0, 'pitiful': 0, 'pitifully': 0, 'pity': 0, 'pitying': 0, 'play': 1, 'played': 1, 'playful': 1, 'playfully': 1, 'playfulness': 1, 'playing': 1, 'plays': 1, 'pleasant': 1, 'pleasantly': 1, 'pleasantries': 1, 'please': 1, 'pleased': 1, 'pleaser': 1, 'pleasers': 1, 'pleases': 1, 'pleasing': 1, 'pleasurable': 1, 'pleasure': 1, 'pleasured': 1, 'pleasures': 1, 'pleasuring': 1, 'poised': 1, 'poison': 0, 'poisoned': 0, 'poisoning': 0, 'poisonous': 0, 'poisons': 0, 'pollute': 0, 'polluted': 0, 'polluter': 0, 'polluters': 0, 'pollutes': 0, 'poor': 0, 'poorer': 0, 'poorest': 0, 'popular': 1, 'popularity': 1, 'popularize': 1, 'popularized': 1, 'popularly': 1, 'positive': 1, 'positively': 1, 'positiveness': 1, 'positiver': 1, 'positives': 1, 'positivism': 1, 'positivity': 1, 'possessive': 0, 'postpone': 0, 'postponed': 0, 'postpones': 0, 'postponing': 0, 'poverty': 0, 'powerful': 1, 'powerless': 0, 'praise': 1, 'praised': 1, 'praises': 1, 'praiseworthy': 1, 'praising': 1, 'pray': 1, 'praying': 1, 'prays': 1, 'prblm': 0, 'prblms': 0, 'precious': 1, 'preciousness': 1, 'prejudice': 0, 'prejudiced': 0, 'prejudices': 0, 'prejudicial': 0, 'prepared': 1, 'pressure': 0, 'pressured': 0, 'pressures': 0, 'pressuring': 0, 'pressurised': 0, 'pressurized': 1, 'pretend': 0, 'pretending': 1, 'pretends': 0, 'prettied': 1, 'prettier': 1, 'pretties': 1, 'prettiest': 1, 'pretty': 1, 'prevent': 1, 'prevented': 1, 'preventing': 0, 'prevents': 1, 'prick': 0, 'pricked': 0, 'pricking': 0, 'prickle': 0, 'prickly': 0, 'pricks': 0, 'pride': 1, 'prison': 0, 'prisoner': 0, 'prisoners': 0, 'privilege': 1, 'privileged': 1, 'privileges': 1, 'prize': 1, 'prized': 1, 'prizefighter': 1, 'prizes': 1, 'proactive': 1, 'problem': 0, 'problematic': 0, 'problematical': 0, 'problems': 0, 'profit': 1, 'profitability': 1, 'profitable': 1, 'profitably': 1, 'profited': 1, 'profiteer': 1, 'profiteering': 0, 'profiteers': 1, 'profiter': 1, 'profiteroles': 1, 'profiting': 1, 'profits': 1, 'progress': 1, 'prominent': 1, 'promiscuity': 0, 'promiscuous': 0, 'promise': 1, 'promised': 1, 'promisee': 1, 'promises': 1, 'promising': 1, 'promissory': 1, 'promote': 1, 'promoted': 1, 'promotes': 1, 'promoting': 1, 'propaganda': 0, 'prosecute': 0, 'prosecuted': 0, 'prosecution': 0, 'prospect': 1, 'prospects': 1, 'prosperous': 1, 'protect': 1, 'protected': 1, 'protects': 1, 'protest': 0, 'protested': 0, 'protesters': 0, 'protesting': 0, 'protests': 0, 'proud': 1, 'prouder': 1, 'proudest': 1, 'proudly': 1, 'provoke': 0, 'provoked': 0, 'provokes': 0, 'provoking': 0, 'pseudoscience': 0, 'puke': 0, 'puked': 0, 'pukes': 0, 'puking': 0, 'pukka': 1, 'punish': 0, 'punishable': 0, 'punished': 0, 'punisher': 0, 'punishes': 0, 'punishing': 0, 'punishment': 0, 'punishments': 0, 'punitive': 0, 'pushy': 0, 'puzzled': 0, 'quaking': 0, 'questionable': 0, 'questioned': 0, 'questioning': 0, 'racism': 0, 'racist': 0, 'racists': 0, 'radian': 1, 'radiance': 1, 'radians': 1, 'radiant': 1, 'radiantly': 1, 'rage': 0, 'raged': 0, 'ragee': 0, 'rages': 0, 'raging': 0, 'rainy': 0, 'rancid': 0, 'rant': 0, 'rants': 0, 'rape': 0, 'raped': 0, 'raper': 0, 'rapers': 0, 'rapes': 0, 'raping': 0, 'rapist': 0, 'rapists': 0, 'rapture': 1, 'raptured': 1, 'rapturous': 1, 'rash': 0, 'ratified': 1, 'reach': 1, 'reached': 1, 'reaches': 1, 'reaching': 1, 'readiness': 1, 'ready': 1, 'reassurance': 1, 'reassure': 1, 'reassured': 1, 'reassures': 1, 'reassuring': 1, 'reassuringly': 1, 'rebel': 0, 'rebelled': 0, 'rebelling': 0, 'rebellion': 0, 'rebellions': 0, 'rebellious': 0, 'rebels': 0, 'recession': 0, 'reckless': 0, 'recommend': 1, 'recommended': 1, 'recommends': 1, 'redeemed': 1, 'reek': 0, 'reeked': 0, 'reeking': 0, 'refuse': 0, 'refused': 0, 'refusing': 0, 'regret': 0, 'regretful': 0, 'regretfully': 0, 'regrets': 0, 'regrettable': 0, 'regrettably': 0, 'regretted': 0, 'regretter': 0, 'regretting': 0, 'reinvigorate': 1, 'reinvigorated': 1, 'reject': 0, 'rejected': 0, 'rejecting': 0, 'rejection': 0, 'rejections': 0, 'rejects': 0, 'rejoice': 1, 'rejoiced': 1, 'rejoices': 1, 'rejoicing': 1, 'relax': 1, 'relaxant': 1, 'relaxation': 1, 'relaxed': 1, 'relaxer': 1, 'relaxers': 1, 'relaxes': 1, 'relaxin': 1, 'relaxing': 1, 'relentless': 1, 'reliant': 1, 'relief': 1, 'reliefs': 1, 'relieve': 1, 'relieved': 1, 'reliever': 1, 'relievers': 1, 'relieves': 1, 'relieving': 1, 'relishing': 1, 'reluctance': 0, 'reluctant': 0, 'reluctantly': 0, 'remarkable': 1, 'remorse': 0, 'remorseful': 0, 'repetitive': 0, 'repress': 0, 'repressed': 0, 'repressing': 0, 'repression': 0, 'repressive': 0, 'repulse': 0, 'repulsed': 0, 'rescue': 1, 'rescued': 1, 'rescues': 1, 'resent': 0, 'resented': 0, 'resentful': 0, 'resenting': 0, 'resentment': 0, 'resentments': 0, 'resents': 0, 'resign': 0, 'resignation': 0, 'resignations': 0, 'resigned': 0, 'resigning': 0, 'resigns': 0, 'resolute': 1, 'resolve': 1, 'resolved': 1, 'resolver': 1, 'resolves': 1, 'resolving': 1, 'respect': 1, 'respectability': 1, 'respectable': 1, 'respected': 1, 'respecter': 1, 'respectful': 1, 'respectfully': 1, 'respecting': 1, 'respective': 1, 'respectively': 1, 'respects': 1, 'responsible': 1, 'responsive': 1, 'restful': 1, 'restless': 0, 'restlessness': 0, 'restore': 1, 'restored': 1, 'restores': 1, 'restoring': 1, 'restrict': 0, 'restricted': 0, 'restricting': 0, 'restriction': 0, 'restricts': 0, 'retained': 1, 'retard': 0, 'retarded': 0, 'retreat': 1, 'revenge': 0, 'revenged': 0, 'revengeful': 0, 'revenger': 0, 'revengers': 0, 'revenges': 0, 'revered': 1, 'revive': 1, 'revives': 1, 'reward': 1, 'rewarded': 1, 'rewarder': 1, 'rewarding': 1, 'rewards': 1, 'rich': 1, 'richer': 1, 'riches': 1, 'richest': 1, 'richly': 1, 'richness': 1, 'ridicule': 0, 'ridiculed': 0, 'ridicules': 0, 'ridiculing': 0, 'ridiculous': 0, 'ridiculously': 0, 'ridiculousness': 0, 'rig': 0, 'rigged': 0, 'rigid': 0, 'rigidity': 0, 'rigidly': 0, 'rigorous': 0, 'rigorously': 0, 'riot': 0, 'riots': 0, 'risk': 0, 'risked': 0, 'riskier': 0, 'riskiest': 0, 'risking': 0, 'risks': 0, 'risky': 0, 'rob': 0, 'robber': 0, 'robed': 0, 'robing': 0, 'robs': 0, 'robust': 1, 'roflcopter': 1, 'romance': 1, 'romanced': 1, 'romancer': 1, 'romancers': 1, 'romances': 1, 'romancing': 1, 'romantic': 1, 'romantically': 1, 'romanticism': 1, 'romanticize': 1, 'romanticized': 1, 'romanticizing': 1, 'romantics': 1, 'rotten': 0, 'rude': 0, 'rudely': 0, 'rudeness': 0, 'ruder': 0, 'rudest': 0, 'ruin': 0, 'ruination': 0, 'ruined': 0, 'ruiner': 0, 'ruing': 0, 'ruining': 0, 'ruinous': 0, 'ruins': 0, 'sabotage': 0, 'sad': 0, 'sadden': 0, 'saddened': 0, 'saddening': 0, 'saddens': 0, 'sadder': 0, 'saddest': 0, 'sadly': 0, 'sadness': 0, 'safe': 1, 'safeguard': 1, 'safeguarding': 1, 'safeguards': 1, 'safekeeping': 1, 'safely': 1, 'safer': 1, 'safes': 1, 'safest': 1, 'safeties': 1, 'safety': 1, 'salient': 1, 'sappy': 0, 'sarcasm': 0, 'sarcasms': 0, 'sarcastic': 0, 'sarcastically': 0, 'satisfaction': 1, 'satisfactions': 1, 'satisfactory': 1, 'satisfied': 1, 'satisfies': 1, 'satisfy': 1, 'satisfying': 1, 'savage': 0, 'savaged': 0, 'savagely': 0, 'savagery': 0, 'savages': 0, 'save': 1, 'saved': 1, 'scam': 0, 'scams': 0, 'scandal': 0, 'scandalous': 0, 'scandals': 0, 'scapegoat': 0, 'scapegoats': 0, 'scare': 0, 'scarecrow': 0, 'scarecrows': 0, 'scared': 0, 'scares': 0, 'scarey': 0, 'scaring': 0, 'scary': 0, 'sceptic': 0, 'sceptical': 0, 'scepticism': 0, 'sceptics': 0, 'scold': 0, 'scoop': 1, 'scorn': 0, 'scornful': 0, 'scream': 0, 'screamed': 0, 'screamers': 0, 'screaming': 0, 'screams': 0, 'screw': 0, 'screwball': 0, 'screwdriver': 1, 'screwdrivers': 1, 'screwed': 0, 'screwing': 0, 'screws': 0, 'screwup': 0, 'screwy': 0, 'scrumptious': 1, 'scumbag': 0, 'secure': 1, 'secured': 1, 'securely': 1, 'secures': 1, 'securing': 1, 'securities': 1, 'securitization': 1, 'security': 1, 'sedition': 0, 'seditious': 0, 'seduced': 0, 'self-confident': 1, 'selfish': 0, 'selfishly': 0, 'selfishness': 0, 'sentence': 1, 'sentenced': 0, 'sentences': 1, 'sentencing': 0, 'sentimental': 1, 'sentimentality': 1, 'serene': 1, 'serious': 0, 'seriously': 0, 'seriousness': 0, 'severe': 0, 'severed': 0, 'severely': 0, 'sexy': 1, 'shake': 0, 'shakedown': 0, 'shaken': 0, 'shakeout': 0, 'shakers': 1, 'shakeup': 0, 'shakily': 0, 'shaking': 0, 'shaky': 0, 'shame': 0, 'shamed': 0, 'shameful': 0, 'shamefully': 0, 'shameless': 0, 'shamelessly': 0, 'shames': 0, 'share': 1, 'shared': 1, 'shares': 1, 'sharing': 1, 'shattered': 0, 'shit': 0, 'shitake': 0, 'shithead': 0, 'shitheads': 0, 'shits': 0, 'shitted': 0, 'shittier': 0, 'shittiest': 0, 'shitting': 0, 'shitty': 0, 'shock': 0, 'shocked': 0, 'shocker': 0, 'shockers': 0, 'shocking': 0, 'shockingly': 0, 'shockproof': 1, 'shocks': 0, 'shook': 0, 'shoot': 0, 'short-sighted': 0, 'shortage': 0, 'shortages': 0, 'shrew': 0, 'shy': 0, 'shying': 0, 'shylock': 0, 'shyly': 0, 'shyness': 0, 'sick': 0, 'sicken': 0, 'sickened': 0, 'sickener': 0, 'sickening': 0, 'sickeningly': 0, 'sickens': 0, 'sigh': 1, 'significance': 1, 'significant': 1, 'silencing': 0, 'sillier': 1, 'sillies': 1, 'silliest': 1, 'silliness': 0, 'silly': 1, 'sin': 0, 'sincere': 1, 'sincerely': 1, 'sincerer': 1, 'sincerest': 1, 'sinful': 0, 'sinister': 0, 'sins': 0, 'skeptic': 0, 'skeptical': 0, 'skepticism': 0, 'skeptics': 0, 'slam': 0, 'slash': 0, 'slashed': 0, 'slashes': 0, 'slashing': 0, 'slavery': 0, 'sleeplessness': 0, 'slicker': 1, 'slickest': 1, 'sluggish': 0, 'slut': 0, 'sluts': 0, 'sluttier': 0, 'sluttiest': 0, 'slutty': 0, 'smart': 1, 'smartass': 0, 'smartasses': 0, 'smarted': 1, 'smarten': 1, 'smarter': 1, 'smartest': 1, 'smartie': 1, 'smarties': 1, 'smarting': 0, 'smartly': 1, 'smartness': 1, 'smarts': 1, 'smarty': 1, 'smear': 0, 'smile': 1, 'smiled': 1, 'smiler': 1, 'smiles': 1, 'smiley': 1, 'smileys': 1, 'smiling': 1, 'smog': 0, 'smother': 0, 'smothered': 0, 'smothering': 0, 'smothers': 0, 'smug': 1, 'smuggle': 0, 'smuggled': 0, 'smuggler': 0, 'smugglers': 0, 'smuggling': 0, 'smugly': 1, 'smugness': 0, 'sneaky': 0, 'snob': 0, 'snobbery': 0, 'snobbish': 0, 'snobby': 0, 'snobs': 0, 'snub': 0, 'snubbed': 0, 'snubbing': 0, 'snubs': 0, 'sobbed': 0, 'sobbing': 0, 'sobering': 0, 'sobs': 0, 'sociable': 1, 'sok': 1, 'solemn': 0, 'solemnity': 0, 'solemnization': 1, 'solemnly': 1, 'solid': 1, 'solidarity': 1, 'solution': 1, 'solutions': 1, 'solve': 1, 'solved': 1, 'solves': 1, 'solving': 1, 'somber': 0, 'son-of-a-bitch': 0, 'soothe': 1, 'soothed': 1, 'soothing': 1, 'sophisticated': 1, 'sore': 0, 'sorrow': 0, 'sorrowful': 0, 'sorrows': 0, 'sorry': 0, 'soulmate': 1, 'spam': 0, 'spammer': 0, 'spammers': 0, 'spamming': 0, 'spark': 1, 'sparkle': 1, 'sparkles': 1, 'sparkling': 1, 'special': 1, 'speculative': 1, 'spirit': 1, 'spirited': 1, 'spite': 0, 'spiteful': 0, 'splendid': 1, 'splendidly': 1, 'splendiferous': 1, 'splendor': 1, 'splendour': 1, 'sprightly': 1, 'stab': 0, 'stabbed': 0, 'stable': 1, 'stabs': 0, 'stall': 0, 'stalled': 0, 'stalling': 0, 'stamina': 1, 'stammer': 0, 'stammerer': 0, 'stammering': 0, 'stammers': 0, 'stampede': 0, 'stank': 0, 'startle': 0, 'startled': 0, 'startles': 0, 'startling': 1, 'startlingly': 0, 'starve': 0, 'starved': 0, 'starves': 0, 'starving': 0, 'steadfast': 1, 'steal': 0, 'stealer': 0, 'stealers': 0, 'stealing': 0, 'steals': 0, 'stealth': 0, 'stealthily': 1, 'stealthy': 0, 'stench': 0, 'stereotype': 0, 'stereotyped': 0, 'stifled': 0, 'stimulate': 1, 'stimulated': 1, 'stimulates': 1, 'stimulating': 1, 'stingy': 0, 'stink': 0, 'stinkbug': 0, 'stinkbugs': 0, 'stinker': 0, 'stinkers': 0, 'stinkiest': 0, 'stinking': 0, 'stinks': 0, 'stinky': 0, 'stolen': 0, 'stop': 0, 'stopped': 0, 'stopping': 0, 'stops': 0, 'stout': 1, 'straight': 1, 'strain': 0, 'strained': 0, 'strainer': 0, 'straining': 0, 'strains': 0, 'strange': 0, 'strangely': 0, 'strangled': 0, 'strength': 1, 'strengthen': 1, 'strengthened': 1, 'strengthening': 1, 'strengthens': 1, 'strengths': 1, 'stress': 0, 'stressed': 0, 'stresses': 0, 'stressful': 0, 'stressing': 0, 'stressless': 1, 'stressor': 0, 'stressors': 0, 'stricken': 0, 'strike': 0, 'strikers': 0, 'strikes': 0, 'strong': 1, 'stronger': 1, 'strongest': 1, 'stronghold': 1, 'strongholds': 1, 'strongly': 1, 'strongman': 1, 'struck': 0, 'struggle': 0, 'struggled': 0, 'struggler': 0, 'strugglers': 0, 'struggles': 0, 'struggling': 0, 'stubborn': 0, 'stubbornly': 0, 'stubbornness': 0, 'stuck': 0, 'stunk': 0, 'stunned': 0, 'stunning': 1, 'stuns': 1, 'stupid': 0, 'stupider': 0, 'stupidest': 0, 'stupidities': 0, 'stupidity': 0, 'stupidly': 0, 'stupidness': 0, 'stupids': 0, 'stutter': 0, 'stuttered': 0, 'stuttering': 0, 'stutters': 0, 'suave': 1, 'submissive': 0, 'submissiveness': 0, 'substantial': 1, 'subversive': 0, 'succeed': 1, 'succeeded': 1, 'succeeding': 1, 'succeeds': 1, 'success': 1, 'successes': 1, 'successful': 1, 'successfully': 1, 'succession': 1, 'successive': 1, 'successor': 1, 'successors': 1, 'suck': 0, 'sucked': 0, 'sucker': 0, 'suckered': 0, 'suckers': 0, 'sucks': 0, 'sucky': 0, 'suffer': 0, 'suffered': 0, 'sufferer': 0, 'sufferers': 0, 'suffering': 0, 'suffers': 0, 'suicidal': 0, 'suicide': 0, 'suing': 0, 'sulking': 0, 'sulky': 0, 'sullen': 0, 'sunnier': 1, 'sunniest': 1, 'sunny': 1, 'sunshine': 1, 'sunshiny': 1, 'super': 1, 'superb': 1, 'superior': 1, 'superiority': 1, 'superiors': 1, 'support': 1, 'supported': 1, 'supporter': 1, 'supporters': 1, 'supporting': 1, 'supportive': 1, 'supports': 1, 'supremacist': 1, 'supremacists': 0, 'supremacy': 1, 'supreme': 1, 'supremely': 1, 'supremo': 1, 'supremos': 1, 'sure': 1, 'surefire': 1, 'surely': 1, 'sureness': 1, 'surer': 1, 'surest': 1, 'surety': 1, 'surprise': 1, 'surprised': 1, 'surprises': 1, 'surprising': 1, 'surprisingly': 1, 'survived': 1, 'surviving': 1, 'survivor': 1, 'suspect': 0, 'suspected': 0, 'suspecting': 0, 'suspects': 0, 'suspend': 0, 'suspended': 0, 'suspicion': 0, 'suspicions': 0, 'suspicious': 0, 'suspiciously': 0, 'sux': 0, 'swear': 0, 'swearing': 0, 'swears': 1, 'sweet': 1, 'sweetheart': 1, 'sweethearts': 1, 'sweetie': 1, 'sweeties': 1, 'sweetly': 1, 'sweetness': 1, 'sweets': 1, 'swift': 1, 'swiftly': 1, 'swindle': 0, 'swindling': 0, 'sympathetic': 1, 'sympathy': 1, 'talent': 1, 'talented': 1, 'talentless': 0, 'talents': 1, 'tantrum': 0, 'tantrums': 0, 'tard': 0, 'tears': 0, 'teas': 1, 'tease': 0, 'teased': 0, 'teaser': 0, 'teasers': 0, 'teases': 0, 'teasing': 0, 'teasingly': 0, 'teaspoon': 1, 'teaspoons': 1, 'temper': 0, 'tempers': 0, 'tendered': 1, 'tenderhearted': 1, 'tendering': 1, 'tenderloin': 0, 'tenderly': 1, 'tenderness': 1, 'tenders': 1, 'tense': 0, 'tensed': 0, 'tenses': 0, 'tensing': 0, 'tension': 0, 'tensioned': 0, 'tensioner': 0, 'tensions': 0, 'terrible': 0, 'terribly': 0, 'terrific': 1, 'terrifically': 1, 'terrified': 0, 'terrifies': 0, 'terrify': 0, 'terrifying': 0, 'terror': 0, 'terrorise': 0, 'terrorised': 0, 'terrorising': 0, 'terrorism': 0, 'terrorist': 0, 'terroristic': 0, 'terrorists': 0, 'terrorize': 0, 'terrorized': 0, 'terrorizes': 0, 'terrorizing': 0, 'terrors': 0, 'thank': 1, 'thanked': 1, 'thankful': 1, 'thankfully': 1, 'thankfulness': 1, 'thanks': 1, 'thief': 0, 'thieve': 0, 'thievery': 0, 'thieves': 0, 'thorny': 0, 'thoughtful': 1, 'thoughtfully': 1, 'thoughtfulness': 1, 'thoughtless': 0, 'threat': 0, 'threaten': 0, 'threatened': 0, 'threatening': 0, 'threatens': 0, 'threating': 0, 'threats': 0, 'thrill': 1, 'thrilled': 1, 'thriller': 1, 'thrillers': 1, 'thrilling': 1, 'thrills': 1, 'thwarted': 0, 'thwarting': 0, 'thwarts': 0, 'ticked': 0, 'timid': 0, 'timidity': 0, 'timidly': 0, 'tired': 0, 'tits': 0, 'tolerance': 1, 'tolerant': 1, 'toothless': 0, 'top': 1, 'tops': 1, 'torn': 0, 'torture': 0, 'tortured': 0, 'torturer': 0, 'torturers': 0, 'tortures': 0, 'torturing': 0, 'torturous': 0, 'totalitarian': 0, 'totalitarianism': 0, 'tough': 0, 'toughen': 1, 'toughened': 1, 'toughens': 0, 'tougher': 1, 'toughest': 0, 'toughie': 0, 'toughing': 0, 'toughness': 0, 'toughy': 0, 'tout': 0, 'touted': 0, 'touting': 0, 'touts': 0, 'tragedies': 0, 'tragedy': 0, 'tragic': 0, 'tragically': 0, 'tranquil': 1, 'tranquility': 1, 'tranquilize': 1, 'tranquilized': 0, 'tranquilizer': 0, 'tranquilizers': 0, 'tranquillity': 1, 'trap': 0, 'trapped': 0, 'trauma': 0, 'traumas': 0, 'traumatic': 0, 'traumatise': 0, 'traumatised': 0, 'traumatising': 0, 'traumatize': 0, 'traumatized': 0, 'traumatizing': 0, 'travesty': 0, 'treason': 0, 'treasonous': 0, 'treasure': 1, 'treasured': 1, 'treasurer': 1, 'treasures': 1, 'treasuries': 1, 'treasuring': 1, 'treasury': 1, 'treat': 1, 'tremble': 0, 'trembled': 0, 'trembler': 0, 'trembles': 0, 'trembling': 0, 'trick': 0, 'tricked': 0, 'tricker': 0, 'trickery': 0, 'trickier': 0, 'trickiest': 0, 'tricking': 1, 'trickled': 1, 'trickles': 1, 'trickling': 0, 'tricks': 0, 'trickster': 0, 'tricksters': 0, 'tricksy': 0, 'tricky': 0, 'trite': 0, 'triumph': 1, 'triumphal': 1, 'triumphant': 1, 'triumphantly': 1, 'triumphed': 1, 'triumphs': 1, 'trivial': 0, 'trivialize': 0, 'trivium': 0, 'trouble': 0, 'troubled': 0, 'troublemaker': 0, 'troublemakers': 0, 'troubler': 0, 'troubles': 0, 'troubleshoot': 1, 'troubleshooter': 1, 'troubleshooting': 1, 'troublesome': 0, 'troubling': 0, 'trueness': 1, 'truer': 1, 'truest': 1, 'truly': 1, 'trust': 1, 'trustable': 1, 'trusted': 1, 'trustee': 1, 'trustees': 1, 'trustful': 1, 'trusting': 1, 'trusts': 1, 'trustworthiness': 1, 'trustworthy': 1, 'trusty': 1, 'truth': 1, 'truthful': 1, 'truthfully': 1, 'truthfulness': 1, 'truths': 1, 'tumor': 0, 'turmoil': 0, 'twat': 0, 'ugh': 0, 'uglier': 0, 'uglies': 0, 'ugliest': 0, 'ugliness': 0, 'ugly': 0, 'unacceptable': 0, 'unappreciated': 0, 'unapproved': 0, 'unattractive': 0, 'unaware': 0, 'unbelievable': 1, 'unbelieving': 0, 'unbiased': 0, 'uncertain': 0, 'uncertainties': 0, 'uncertainty': 0, 'unclear': 0, 'uncomfortable': 0, 'uncomfortably': 0, 'unconcerned': 0, 'unconfirmed': 0, 'uncontrollable': 0, 'uncontrollably': 0, 'uncontrolled': 0, 'unconvinced': 0, 'uncredited': 0, 'undecided': 0, 'underestimate': 0, 'underestimated': 0, 'underestimates': 0, 'undermine': 0, 'undermined': 0, 'undermines': 0, 'undermining': 0, 'undeserving': 0, 'undesirable': 0, 'unease': 0, 'uneasiness': 0, 'uneasy': 0, 'unemployment': 0, 'unequal': 0, 'unethical': 0, 'unfair': 0, 'unfocused': 0, 'unfortunate': 0, 'unfortunately': 0, 'unfriendly': 0, 'unfulfilled': 0, 'ungrateful': 0, 'ungratefulness': 0, 'unhappiest': 0, 'unhappily': 0, 'unhappiness': 0, 'unhappy': 0, 'unhealthy': 0, 'unified': 1, 'unimportant': 0, 'unimpressed': 0, 'unimpressive': 0, 'unintelligent': 0, 'uninvolved': 0, 'united': 1, 'unjust': 0, 'unkind': 0, 'unlovable': 0, 'unloved': 0, 'unlovely': 0, 'unloving': 0, 'unmatched': 0, 'unmotivated': 0, 'unpleasant': 0, 'unprofessional': 0, 'unprotected': 0, 'unsatisfied': 0, 'unsavory': 0, 'unsecured': 0, 'unsettled': 0, 'unsophisticated': 0, 'unstable': 0, 'unstoppable': 0, 'unsuccessful': 0, 'unsuccessfully': 0, 'unsupported': 0, 'unsure': 0, 'unwanted': 0, 'unwelcome': 0, 'unworthy': 0, 'upset': 0, 'upsets': 0, 'upsetting': 0, 'uptight': 0, 'urgent': 1, 'useful': 1, 'usefully': 1, 'usefulness': 1, 'useless': 0, 'uselessly': 0, 'uselessness': 0, 'v.v': 0, 'vague': 0, 'vain': 0, 'validate': 1, 'validated': 1, 'validates': 1, 'validating': 1, 'valuable': 1, 'valuables': 1, 'value': 1, 'valued': 1, 'values': 1, 'valuing': 1, 'vanity': 0, 'verdict': 1, 'verdicts': 1, 'vested': 1, 'vexation': 0, 'vexing': 0, 'vibrant': 1, 'vicious': 0, 'viciously': 0, 'viciousness': 0, 'victim': 0, 'victimhood': 0, 'victimise': 0, 'victimised': 0, 'victimization': 0, 'victimize': 0, 'victimized': 0, 'victimizing': 0, 'victimless': 1, 'victims': 0, 'vigilant': 1, 'vigor': 1, 'vigoroso': 1, 'vigorously': 1, 'vigour': 1, 'vile': 0, 'villain': 0, 'villainous': 0, 'villains': 0, 'villainy': 0, 'vindicate': 1, 'vindicated': 1, 'vindicates': 1, 'violate': 0, 'violated': 0, 'violates': 0, 'violating': 0, 'violation': 0, 'violations': 0, 'violator': 0, 'violators': 0, 'violence': 0, 'violent': 0, 'violently': 0, 'virtue': 1, 'virtues': 1, 'virtuosa': 1, 'virtuosas': 1, 'virtuose': 1, 'virtuosi': 1, 'virtuoso': 1, 'virtuosos': 1, 'virtuous': 1, 'virulent': 0, 'vision': 1, 'visionary': 1, 'visioning': 1, 'visions': 1, 'vital': 1, 'vitality': 1, 'vitally': 1, 'vitals': 1, 'vitamin': 1, 'vitriolic': 0, 'vivacious': 1, 'vociferous': 0, 'vulnerabilities': 0, 'vulnerability': 0, 'vulnerable': 0, 'vulture': 0, 'vultures': 0, 'walkout': 0, 'wanker': 0, 'want': 1, 'war': 0, 'warfare': 0, 'warm': 1, 'warmed': 1, 'warmer': 1, 'warmers': 1, 'warmest': 1, 'warmhearted': 1, 'warming': 1, 'warmish': 1, 'warmly': 1, 'warmness': 1, 'warmonger': 0, 'warmongering': 0, 'warmongers': 0, 'warms': 1, 'warmth': 1, 'warmup': 1, 'warmups': 1, 'warn': 0, 'warned': 0, 'warning': 0, 'warnings': 0, 'warns': 0, 'warring': 0, 'wars': 0, 'warsaw': 0, 'warship': 0, 'warships': 0, 'waste': 0, 'wasted': 0, 'wasting': 0, 'wavering': 0, 'weak': 0, 'weaken': 0, 'weakened': 0, 'weakening': 0, 'weakens': 0, 'weaker': 0, 'weakest': 0, 'weakling': 0, 'weaklings': 0, 'weakly': 0, 'weakness': 0, 'weaknesses': 0, 'wealth': 1, 'wealthier': 1, 'wealthiest': 1, 'wealthy': 1, 'weapon': 0, 'weaponry': 0, 'weapons': 0, 'weary': 0, 'weep': 0, 'weepers': 0, 'weeping': 0, 'weeps': 0, 'weepy': 0, 'weird': 0, 'weirder': 0, 'weirdest': 0, 'weirdly': 0, 'weirdness': 0, 'weirdo': 0, 'weirdos': 0, 'weirds': 0, 'weirdy': 0, 'welcome': 1, 'welcomed': 1, 'welcomes': 1, 'welcoming': 1, 'well': 1, 'welled': 1, 'wellies': 1, 'welling': 1, 'wellness': 1, 'wells': 1, 'wellspring': 1, 'welly': 1, 'wept': 0, 'whimsical': 1, 'whine': 0, 'whined': 0, 'whiner': 0, 'whiners': 0, 'whines': 0, 'whiney': 0, 'whining': 0, 'whitewash': 1, 'whore': 0, 'whored': 0, 'whorehouse': 0, 'whores': 0, 'wicked': 0, 'wickedest': 0, 'wickedly': 0, 'wickedness': 0, 'widowed': 0, 'willingness': 1, 'wimp': 0, 'wimps': 0, 'wimpy': 0, 'win': 1, 'winnable': 1, 'winner': 1, 'winners': 1, 'winning': 1, 'winnings': 1, 'wins': 1, 'wisdom': 1, 'wise': 1, 'wised': 1, 'wiseguys': 1, 'wisely': 1, 'wiser': 1, 'wisest': 1, 'wish': 1, 'wishes': 1, 'wishing': 1, 'witch': 0, 'withdrawal': 1, 'woe': 0, 'woeful': 0, 'woefully': 0, 'woes': 0, 'won': 1, 'wonderful': 1, 'wonderfully': 1, 'wonderfulness': 1, 'woo': 1, 'woohoo': 1, 'woot': 1, 'worn': 0, 'worried': 0, 'worriedly': 0, 'worrier': 0, 'worriers': 0, 'worries': 0, 'worrisome': 0, 'worry': 0, 'worrying': 0, 'worse': 0, 'worsen': 0, 'worsened': 0, 'worsening': 0, 'worsens': 0, 'worser': 0, 'worship': 1, 'worshiped': 1, 'worshiper': 1, 'worshipers': 1, 'worshipful': 1, 'worshiping': 1, 'worshipped': 1, 'worshipper': 1, 'worshippers': 1, 'worshipping': 1, 'worships': 1, 'worst': 0, 'worth': 1, 'worthless': 0, 'worthwhile': 1, 'worthy': 1, 'wow': 1, 'wowed': 1, 'wowing': 1, 'wows': 1, 'wowser': 0, 'wowsers': 1, 'wreck': 0, 'wrong': 0, 'wronged': 0, 'yay': 1, 'yeah': 1, 'yearning': 1, 'yeees': 1, 'yep': 1, 'yes': 1, 'youthful': 1, 'yucky': 0, 'yummy': 1, 'zealot': 0, 'zealots': 0, 'zealous': 1}\n"
     ]
    }
   ],
   "source": [
    "# recode polarity to binary\n",
    "lexicons_recoded = {}\n",
    "for (k, v) in lexicons_filtered.items():\n",
    "    if v >= 0:\n",
    "        lexicons_recoded[k] = 1\n",
    "    else:\n",
    "        lexicons_recoded[k] = 0\n",
    "print(lexicons_recoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def baseline_model(X_train, y_train, X_test, y_test):\n",
    "    # implementation of PAC\n",
    "    test_error = 0\n",
    "    return test_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def static_clustering(X_train, y_train, X_test, y_test):\n",
    "    # initiate vector space\n",
    "    vector_space = VectorSpace()\n",
    "\n",
    "    # injecting X_test words as points in the vector space\n",
    "    X_test.apply(lambda x: vector_space.tweet_to_vector_space(x, model=model))\n",
    "    # vector_space.plot_points(n=100)\n",
    "\n",
    "    # injecting lexicons as centroids\n",
    "    for (word, polarity) in lexicons_recoded.items():\n",
    "        vector_space.vader_to_vector_space(word, polarity, model = model)\n",
    "\n",
    "    # assigning static clusters\n",
    "    vector_space.assign_static_clusters()\n",
    "\n",
    "    # calculating y_test_est\n",
    "    y_test_est = []\n",
    "    y_test_est.append(X_test.apply(lambda x: cal_polarity_of_tweet((x, vector_space, model))))\n",
    "\n",
    "    # calculate loss\n",
    "    test_error = loss_fn(input = y_test_est, target = y_test)\n",
    "\n",
    "    return test_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def dynamic_clustering(X_train, y_train, X_test, y_test):\n",
    "    # initiate vector space\n",
    "    vector_space = VectorSpace()\n",
    "\n",
    "    # injecting X_train words as points in the vector space\n",
    "    X_train.apply(lambda x: vector_space.tweet_to_vector_space(x, model=model))\n",
    "\n",
    "    # injecting lexicons as centroids\n",
    "    for (word, polarity) in lexicons_recoded.items():\n",
    "        vector_space.vader_to_vector_space(word, polarity, model = model)\n",
    "\n",
    "    # assigning dynamic clusters\n",
    "    vector_space.assign_dynamic_clusters()\n",
    "\n",
    "    #injecting X_test words as points in the vector space\n",
    "    X_test.apply(lambda x: vector_space.tweet_to_vector_space(x, model=model))\n",
    "\n",
    "    # assigning static clusters, as the test points still have no clusters\n",
    "    vector_space.assign_static_clusters()\n",
    "\n",
    "    # calculating y_test_est\n",
    "    y_test_est = []\n",
    "    y_test_est.append(X_test.apply(lambda x: cal_polarity_of_tweet((x, vector_space, model))))\n",
    "\n",
    "    # calculate loss\n",
    "    test_error = loss_fn(input = y_test_est, target = y_test)\n",
    "    return test_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_fold 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/lx/ncb2g6ds77x94qt50qpgwq840000gn/T/ipykernel_20965/634749024.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_index\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCV\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cur_fold {0}/{1}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mK\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m     \u001B[0mX_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m     \u001B[0my_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mX_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "# cross validation for selecting models\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "X = tweets['cleaned_text']\n",
    "y = tweets.target\n",
    "Models = [baseline_model, static_clustering, dynamic_clustering]\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "K = 5\n",
    "iterations = 10 # iterations of re-allocating centroids\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(CV.split(X,y)):\n",
    "    print('cur_fold {0}/{1}'.format(k+1,K))\n",
    "    X_train = torch.Tensor(X[train_index])\n",
    "    y_train = torch.Tensor(y[train_index])\n",
    "    X_test = torch.Tensor(X[test_index] )\n",
    "    y_test = torch.Tensor(y[test_index] )\n",
    "    for individual_model in Models:\n",
    "        # print('cur model being tested {0}'.format(i))\n",
    "        test_error, final_train_loss = individual_model(X_train, y_train, X_test, y_test)\n",
    "        # print(test_error)\n",
    "        test_error = test_error.detach().numpy()\n",
    "        test_errors.append(test_error)\n",
    "        train_errors.append(final_train_loss)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "3        [[-1.2275    0.61425   0.23204   0.4787   -0.5...\n4        [[-7.0756e-01 -1.2247e+00  8.7766e-02  2.7264e...\n5        [[-0.52391   1.1214    0.49329  -0.24598  -1.0...\n6        [[-9.3968e-01  5.3473e-01  4.5326e-01  4.2178e...\n7        [[ 3.0260e-01  6.9964e-01 -3.4578e-03 -5.8919e...\n                               ...                        \n19995    [[-1.4197   -0.59392   0.034198  0.7004    0.1...\n19996    [[-1.0864   -0.61674   0.33613   0.43232  -0.2...\n19997    [[ 5.7749e-02  1.3264e+00 -1.6871e-02 -5.5858e...\n19998    [[-9.4931e-01 -5.5718e-01  1.3540e-01 -1.2416e...\n19999    [[-2.4857   -0.82327   0.31095  -0.42148  -1.6...\nName: tokenized_text, Length: 16000, dtype: object"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tweets['tokenized_text']\n",
    "x[train_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f9a0a7ae4c556cc9d70b63c8d6e054a1e46c823d790d1334b23650b163d6b82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
